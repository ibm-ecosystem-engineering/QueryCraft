{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f01177-1724-4285-8bcb-f91647e00926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "from sql_metadata import Parser\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import logging\n",
    "import ibm_db\n",
    "\n",
    "import sqlite3\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from datetime import datetime\n",
    "import os\n",
    "from math import ceil\n",
    "import random\n",
    "import sys\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54e7189-c04d-4ee3-92cc-c8805db23fd8",
   "metadata": {},
   "source": [
    "### Helper variables Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb4654f-bec1-49cc-b15d-f154e62823bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_keywords_list = [\n",
    "    \"TOP\",\"EXISTS\",\"INTERSECT\",\"SELECT\",\"DISTINCT\",\"RANK\",\"AS\",\n",
    "    \"WHERE\",\"AND\",\"OR\",\"BETWEEN\",\"LIKE\",\"COUNT\",\"SUM\",\"AVG\",\n",
    "    \"MIN\",\"MAX\",\"GROUP BY\",\"ORDER BY\",\"DESC\",\"OFFSET\",\"FETCH\",\n",
    "    \"INNER JOIN\",\"LEFT JOIN\",\"RIGHT JOIN\",\"FULL JOIN\",\"UNION\",\n",
    "    \"HAVING\",\"JOIN\"\n",
    "]\n",
    "aggregate_keywords = [\"COUNT\",\"SUM\",\"AVG\",\"MIN\",\"MAX\",\"TOP\"]\n",
    "rank_keywords = [\"RANK\"]\n",
    "fillter_keywords = [\"GROUP BY\",\"ORDER BY\",\"FILTER\",\"HAVING\",\"EXISTS\"]\n",
    "join_keywords = [\n",
    "    \"JOIN\",\"INNER JOIN\",\"LEFT JOIN\",\"RIGHT JOIN\",\"FULL JOIN\",\"UNION\",\"INTERSECT\"\n",
    "]\n",
    "orderby_keywords = [\"ORDER BY\"]\n",
    "groupby_keywords = [\"GROUP BY\"]\n",
    "where_keywords =[\"WHERE\"]\n",
    "date_keywords =[\n",
    "    \"NOW\",\"GETDATE\",\"CURRENT_TIMESTAMP\",\"DATEDIFF\",\"DATEADD\",\"YEAR\",\"DAY\",\"MONTH\"\n",
    "]\n",
    "keyword_pattern = re.compile(r'\\b(?:' + '|'.join(query_keywords_list) + r')\\b', re.IGNORECASE)\n",
    "\n",
    "def calculate_classification_new(df):\n",
    "    ## Create new 3 columns \n",
    "    df[\"Expected count\"] = df.index\n",
    "    df[\"Expected difficulty\"] = df.index\n",
    "    df[\"Expected classification_new\"] = df.index\n",
    "    for index, row in df.iterrows():\n",
    "        sql = row[\"expected query\"]\n",
    "        count =0\n",
    "        classification =\"\"\n",
    "        for keyword in query_keywords_list:\n",
    "            if keyword in sql:\n",
    "                count=count+1\n",
    "                if keyword in orderby_keywords:\n",
    "                    classification = \"ORDER BY\"\n",
    "                elif keyword in groupby_keywords:\n",
    "                    classification = \"GROUP BY\"\n",
    "                elif keyword in aggregate_keywords:\n",
    "                    classification = \"AGGREGATE/RATIO\"\n",
    "                elif keyword in join_keywords:\n",
    "                    classification = \"JOIN\"\n",
    "                elif keyword in where_keywords:\n",
    "                    classification = \"WHERE\"\n",
    "                elif keyword in date_keywords:\n",
    "                    classification = \"DATE\"\n",
    "                ## join  for category \n",
    "                ## pre-trained codellama model what type of query are not correct.\n",
    "\n",
    "        if count < 6:\n",
    "            df.at[index,'Expected difficulty'] =\"simple\"\n",
    "        elif count > 5 and count < 9:\n",
    "            df.at[index,'Expected difficulty'] =\"moderate\"\n",
    "        else:\n",
    "            df.at[index,'Expected difficulty'] =\"challenging\"\n",
    "        if classification == '':\n",
    "            classification = 'SELECT'\n",
    "\n",
    "        df.at[index,'Expected classification_new'] = classification\n",
    "        df.at[index,'Expected count'] =count\n",
    "\n",
    "\n",
    "    ## Create new 3 columns \n",
    "    df[\"Predicted count\"] = df.index\n",
    "    df[\"Predicted difficulty\"] = df.index\n",
    "    df[\"Predicted classification_new\"] = df.index\n",
    "    for index, row in df.iterrows():\n",
    "        sql = row[\"generated query\"]\n",
    "        count =0\n",
    "        classification =\"\"\n",
    "        for keyword in query_keywords_list:\n",
    "            if keyword in sql:\n",
    "                count=count+1\n",
    "                if keyword in orderby_keywords:\n",
    "                    classification = \"ORDER BY\"\n",
    "                elif keyword in groupby_keywords:\n",
    "                    classification = \"GROUP BY\"\n",
    "                elif keyword in aggregate_keywords:\n",
    "                    classification = \"AGGREGATE/RATIO\"\n",
    "                elif keyword in join_keywords:\n",
    "                    classification = \"JOIN\"\n",
    "                elif keyword in where_keywords:\n",
    "                    classification = \"WHERE\"\n",
    "                elif keyword in date_keywords:\n",
    "                    classification = \"DATE\"\n",
    "                ## join  for category \n",
    "                ## pre-trained codellama model what type of query are not correct.\n",
    "\n",
    "        if count < 6:\n",
    "            df.at[index,'Predicted difficulty'] =\"simple\"\n",
    "        elif count > 5 and count < 9:\n",
    "            df.at[index,'Predicted difficulty'] =\"moderate\"\n",
    "        else:\n",
    "            df.at[index,'Predicted difficulty'] =\"challenging\"\n",
    "        if classification == '':\n",
    "            classification = 'SELECT'\n",
    "\n",
    "        df.at[index,'Predicted classification_new'] = classification\n",
    "        df.at[index,'Predicted count'] =count\n",
    "    return df\n",
    "\n",
    "def calculate_classification(df):\n",
    "    ## Create new 3 columns \n",
    "    df[\"Expected count\"] = df.index\n",
    "    df[\"Expected difficulty\"] = df.index\n",
    "    df[\"Expected classification\"] = df.index\n",
    "    for index, row in df.iterrows():\n",
    "        sql = row[\"expected query\"]\n",
    "        count =0\n",
    "        classification =\"\"\n",
    "        for keyword in query_keywords_list:\n",
    "            if keyword in sql:\n",
    "                count=count+1\n",
    "                if keyword in rank_keywords:\n",
    "                    classification = \"RANK\"\n",
    "                elif keyword in fillter_keywords:\n",
    "                    classification = \"FILTER\"\n",
    "                elif keyword in aggregate_keywords:\n",
    "                    classification = \"AGGREGATE\"\n",
    "                elif keyword in join_keywords:\n",
    "                    classification = \"JOIN\"\n",
    "                ## join  for category \n",
    "                ## pre-trained codellama model what type of query are not correct.\n",
    "\n",
    "        if count < 6:\n",
    "            df.at[index,'Expected difficulty'] =\"simple\"\n",
    "        elif count > 5 and count < 9:\n",
    "            df.at[index,'Expected difficulty'] =\"moderate\"\n",
    "        else:\n",
    "            df.at[index,'Expected difficulty'] =\"challenging\"\n",
    "        if classification == '':\n",
    "            classification = 'SELECT'\n",
    "\n",
    "        df.at[index,'Expected classification'] = classification\n",
    "        df.at[index,'Expected count'] =count\n",
    "\n",
    "        ## Create new 3 columns \n",
    "    df[\"Predicted count\"] = df.index\n",
    "    df[\"Predicted difficulty\"] = df.index\n",
    "    df[\"Predicted classification\"] = df.index\n",
    "    for index, row in df.iterrows():\n",
    "        sql = row[\"generated query\"]\n",
    "        count =0\n",
    "        classification =\"\"\n",
    "        for keyword in query_keywords_list:\n",
    "            if keyword in sql:\n",
    "                count=count+1\n",
    "                if keyword in rank_keywords:\n",
    "                    classification = \"RANK\"\n",
    "                elif keyword in fillter_keywords:\n",
    "                    classification = \"FILTER\"\n",
    "                elif keyword in aggregate_keywords:\n",
    "                    classification = \"AGGREGATE\"\n",
    "                elif keyword in join_keywords:\n",
    "                    classification = \"JOIN\"\n",
    "                ## join  for category \n",
    "                ## pre-trained codellama model what type of query are not correct.\n",
    "\n",
    "        if count < 6:\n",
    "            df.at[index,'Predicted difficulty'] =\"simple\"\n",
    "        elif count > 5 and count < 9:\n",
    "            df.at[index,'Predicted difficulty'] =\"moderate\"\n",
    "        else:\n",
    "            df.at[index,'Predicted difficulty'] =\"challenging\"\n",
    "        if classification == '':\n",
    "            classification = 'SELECT'\n",
    "\n",
    "        df.at[index,'Predicted classification'] = classification\n",
    "        df.at[index,'Predicted count'] =count\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def create_db_and_table(db_name):\n",
    "#     # Connect to SQLite database (or create it if it doesn't exist)\n",
    "#     conn = sqlite3.connect(f\"{db_name}.db\")\n",
    "#     cursor = conn.cursor()\n",
    "    \n",
    "#     # Create table\n",
    "#     cursor.execute('''\n",
    "#         CREATE TABLE IF NOT EXISTS contract (\n",
    "#             id TEXT ,\n",
    "#             supplier TEXT,\n",
    "#             services TEXT,\n",
    "#             effective_date TEXT,\n",
    "#             keywords TEXT,\n",
    "#             document_type TEXT,\n",
    "#             expiration_date TEXT,\n",
    "#             created_by TEXT,\n",
    "#             region TEXT,\n",
    "#             tcv REAL,\n",
    "#             term_type TEXT,\n",
    "#             title TEXT,\n",
    "#             keyword TEXT,\n",
    "#             status TEXT,\n",
    "#             functions TEXT,\n",
    "#             countries TEXT,\n",
    "#             regions TEXT\n",
    "#         )\n",
    "#     ''')\n",
    "    \n",
    "#     # Commit changes and close connection\n",
    "#     conn.commit()\n",
    "#     conn.close()\n",
    "\n",
    "\n",
    "\n",
    "# def check_database_schema(db_path):\n",
    "#     # Connect to the SQLite database\n",
    "#     conn = sqlite3.connect(db_path)\n",
    "#     cursor = conn.cursor()\n",
    "    \n",
    "#     # Fetch and print all table names in the database\n",
    "#     cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "#     tables = cursor.fetchall()\n",
    "#     print(\"Tables in the database:\", tables)\n",
    "    \n",
    "#     # Check for 'contract' table and print its schema\n",
    "#     cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name='contract';\")\n",
    "#     if cursor.fetchone():\n",
    "#         print(\"Table 'contract' exists. Schema:\")\n",
    "#         cursor.execute(\"PRAGMA table_info('contract');\")\n",
    "#         columns = cursor.fetchall()\n",
    "#         for column in columns:\n",
    "#             print(column)\n",
    "#     else:\n",
    "#         print(\"Table 'contract' does not exist in the database.\")\n",
    "\n",
    "#     # Close the connection\n",
    "#     conn.close()\n",
    "\n",
    "\n",
    "def isValidSQL(sql, db):\n",
    "    conn = sqlite3.connect(db)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "    except:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def query_processing(row,expected_query_column,generated_query_column):\n",
    "    g_str =''\n",
    "    p_str=''\n",
    "    \n",
    "    if ';' not in row[expected_query_column]:\n",
    "        g_str = row[expected_query_column]+\" ;\"\n",
    "    else:\n",
    "        g_str = row[expected_query_column]\n",
    "    \n",
    "    if ';' not in str(row[generated_query_column]):\n",
    "        p_str = str(row[generated_query_column])+\" ;\"\n",
    "    else:\n",
    "        p_str = str(row[generated_query_column]).split(\";\")[0]\n",
    "        \n",
    "    p_str = p_str.replace(\"> =\", \">=\").replace(\"< =\", \"<=\").replace(\"! =\", \"!=\")\n",
    "    \n",
    "    g_str = g_str.replace('``` ',\"\").replace('`',\"\")\n",
    "    p_str = p_str.replace('``` ',\"\").replace('`',\"\")\n",
    "    g_str = g_str.replace('\" ',\"\")\n",
    "    p_str = p_str.replace('\" ',\"\")\n",
    "    p_str = p_str.replace('### Expected Output:   ',\"\").replace('`',\"\")\n",
    "    p_str = p_str.replace('Note:',\"\")\n",
    "    p_str = p_str.replace(' Ex',\"\")\n",
    "    p_str = p_str.replace('Here is the',\"\")\n",
    "    p_str = p_str.split(\"### Explanation:\")[0]\n",
    "    p_str = p_str.split(\"Explanation: \")[0]\n",
    "    p_str = p_str.split(\": Explanation:\")[0]\n",
    "    p_str = p_str.split(\"Explanation:\")[0]\n",
    "    \n",
    "    p_str = p_str.replace('ILIKE',\"LIKE\")\n",
    "    p_str = p_str.replace('ilike',\"LIKE\")\n",
    "    \n",
    "    if \"### Response:\" in p_str:\n",
    "        p_str = p_str.split(\"### Response:\")[1]\n",
    "    p_str = p_str.replace(\"###\",\"\")\n",
    "    \n",
    "    \n",
    "   \n",
    "    p_str_val = p_str.split(\": Answer:\")\n",
    "    if len(p_str_val) ==2:\n",
    "        p_str = p_str_val[1]\n",
    "    p_str_val = p_str.split(\": Query:\")\n",
    "    if len(p_str_val) ==2:\n",
    "        p_str = p_str_val[1]\n",
    "    \n",
    "    if \"This query\" in p_str:\n",
    "         p_str = p_str.split(\"This query\")[0]\n",
    "    if \"The query\" in p_str:\n",
    "         p_str = p_str.split(\"The query\")[0]     \n",
    "    if \"The above query\" in p_str:\n",
    "         p_str = p_str.split(\"The above query\")[0]\n",
    "    if \"planation:\" in p_str:\n",
    "         p_str = p_str.split(\"planation:\")[0]\n",
    "    if \"This queries\" in p_str:\n",
    "         p_str = p_str.split(\"This queries\")[0]\n",
    "    if \"noqa: E501\" in p_str:\n",
    "         p_str = p_str.split(\"noqa: E501\")[0]\n",
    "\n",
    "    p_str = p_str.split(\": Result:\")[0]\n",
    "    p_str = p_str.split(\"INST \")[0]\n",
    "    p_str = p_str.split(\" INST\")[0]\n",
    "    p_str = p_str.split(\" find \")[0]\n",
    "    p_str = p_str.split(\" INST)\")[0]\n",
    "    \n",
    "    p_str = p_str.strip()\n",
    "    g_str = g_str.strip()\n",
    "    p_str = p_str.replace(\"#\",\"\")\n",
    "    p_str = reformat_query(p_str)\n",
    "    p_str = replace_cur_year(p_str)\n",
    "    \n",
    "    if \"select\" in p_str.lower():\n",
    "        if ':' in p_str:\n",
    "            p_str=p_str.replace(\":\",\"\")\n",
    "        if ';' not in p_str:\n",
    "            p_str=p_str+' ;'\n",
    "    return g_str, p_str\n",
    "\n",
    "\n",
    "def get_category(query):\n",
    "    query_keywords_list = [\"TOP\",\"EXISTS\",\"INTERSECT\",\"SELECT\",\"DISTINCT\",\"TOP\",\"RANK\",\"AS\",\"WHERE\",\"AND\",\"OR\",\"BETWEEN\",\"LIKE\",\"COUNT\",\"SUM\",\"AVG\",\"MIN\",\"MAX\",\"GROUP BY\",\"ORDER BY\",\"DESC\",\"OFFSET\",\"FETCH\",\"INNER JOIN\",\"LEFT JOIN\",\"RIGHT JOIN\",\"FULL JOIN\",\"UNION\",\"HAVING\",\"JOIN\"]\n",
    "    aggregate_keywords = [\"COUNT\",\"SUM\",\"AVG\",\"MIN\",\"MAX\",\"TOP\"]\n",
    "    rank_keywords = [\"RANK\"]\n",
    "    fillter_keywords = [\"GROUP BY\",\"ORDER BY\",\"FILTER\",\"HAVING\",\"EXISTS\"]\n",
    "    join_keywords = [\"JOIN\",\"INNER JOIN\",\"LEFT JOIN\",\"RIGHT JOIN\",\"FULL JOIN\",\"UNION\",\"INTERSECT\"]\n",
    "\n",
    "    count =0\n",
    "    orderby_keywords = [\"ORDER BY\"]\n",
    "    groupby_keywords = [\"GROUP BY\"]\n",
    "    where_keywords =[\"WHERE\"]\n",
    "    date_keywords =[\"NOW\",\"GETDATE\",\"CURRENT_TIMESTAMP\",\"DATEDIFF\",\"DATEADD\",\"YEAR\",\"DAY\",\"MONTH\"]\n",
    "    for keyword in query_keywords_list:\n",
    "        if isinstance(query,str) and keyword in query:\n",
    "            count=count+1\n",
    "            if keyword in orderby_keywords:\n",
    "                classification = \"ORDER BY\"\n",
    "            elif keyword in groupby_keywords:\n",
    "                classification = \"GROUP BY\"\n",
    "            elif keyword in aggregate_keywords:\n",
    "                classification = \"AGGREGATE/RATIO\"\n",
    "            elif keyword in join_keywords:\n",
    "                classification = \"JOIN\"\n",
    "            elif keyword in where_keywords:\n",
    "                classification = \"WHERE\"\n",
    "            elif keyword in date_keywords:\n",
    "                classification = \"DATE\"\n",
    "    if count < 6:\n",
    "        classification=\"simple\"\n",
    "    elif count > 5 and count < 9:\n",
    "        classification=\"moderate\"\n",
    "    else:\n",
    "        classification =\"challenging\"\n",
    "    if classification == '':\n",
    "        classification = 'SELECT'\n",
    "    return classification\n",
    "\n",
    "\n",
    "def replace_cur_year(query: str) -> str:\n",
    "    return re.sub(\n",
    "        \"YEAR\\s*\\(\\s*CURDATE\\s*\\(\\s*\\)\\s*\\)\\s*\", \"2020\", query, flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "def formaterAndCaller_db2(row,schema_name,expected_query_column,generated_query_column):\n",
    "    conn = db2_connector.db2_connectorWithSchema(schema_name)\n",
    "\n",
    "    g_str = row[expected_query_column]\n",
    "    p_str =row[generated_query_column]\n",
    "\n",
    "    eval_score1 =0\n",
    "    eval_score,error,result = eval_exec_match_db2(conn,conn,p_str, g_str)\n",
    "    ## For query correction:\n",
    "    g_str_p1,p_str_p1 = query_processing(row,expected_query_column,generated_query_column)\n",
    "    eval_score1 ,error,result = eval_exec_match_db2(conn,conn,p_str_p1, g_str_p1)\n",
    "\n",
    "    return eval_score,eval_score1,error,result\n",
    "\n",
    "def reformat_query(query: str) -> str:\n",
    "    t_stars = [\"t1.*\", \"t2.*\", \"t3.*\", \"T1.*\", \"T2.*\", \"T3.*\"]\n",
    "    for ts in t_stars:\n",
    "        query = query.replace(ts, \"*\")\n",
    "    return query\n",
    "\n",
    "\n",
    "def error_handling(e):\n",
    "    error =\"None\"\n",
    "    if 'no such column' in e:\n",
    "            error =\"No such column\"\n",
    "    elif 'syntax error' in e:\n",
    "            error = \"Syntax error\"\n",
    "    elif 'no such table' in e:\n",
    "            error = \"No such table\"\n",
    "    elif 'ambiguous column name' in e:\n",
    "            error = \"Ambiguous column name\"\n",
    "    else:\n",
    "        error = e\n",
    "    return error\n",
    "\n",
    "\n",
    "def formaterAndCaller_db2(df,row):\n",
    "    conn = db2_connector.db2_connectorWithSchema(row[\"db_id\"])\n",
    "\n",
    "    g_str = row[\"query\"]+\";\"\n",
    "    p_str =row[\"model_op\"]\n",
    "\n",
    "    eval_score1 =0\n",
    "    eval_score,error,result = eval_exec_match_db2(conn,conn,p_str, g_str)\n",
    "    ## For query correction:\n",
    "    if \"model_op1\" in df.columns:\n",
    "        p_str_p =row[\"model_op1\"]\n",
    "        eval_score1 ,error,result = eval_exec_match_db2(conn,conn,p_str_p, g_str)\n",
    "\n",
    "    return eval_score,eval_score1,error,result\n",
    "    \n",
    "\n",
    "def eval_exec_match_db2(db2_conn, db2_conn1, p_str, g_str):\n",
    "    \"\"\"\n",
    "    Return 1 if the values between prediction and gold are matching\n",
    "    in the corresponding index. Currently not support multiple col_unit(pairs).\n",
    "    \"\"\"\n",
    "    error = 'None'\n",
    "    result = \"error\"\n",
    "    value = False\n",
    "\n",
    "    try:\n",
    "        stmt = ibm_db.exec_immediate(db2_conn, p_str)\n",
    "        p_res = ibm_db.fetch_assoc(stmt)\n",
    "    except Exception as e:\n",
    "        error = error_handling(str(e))\n",
    "        return value, error, result\n",
    "\n",
    "    try:\n",
    "        stmt = ibm_db.exec_immediate(db2_conn1, g_str)\n",
    "        q_res = ibm_db.fetch_assoc(stmt)\n",
    "    except Exception as e:\n",
    "        error = error_handling(str(e))\n",
    "        return value, error, result\n",
    "\n",
    "    orders_matter = False\n",
    "    if q_res is not None and not isinstance(p_res,bool) and not isinstance(q_res,bool) :\n",
    "        value, result = result_eq_db2(p_res, q_res, order_matters=orders_matter)\n",
    "\n",
    "    return value, error, result\n",
    "\n",
    "\n",
    "def result_eq(result1, result2, order_matters):\n",
    "    result =\"None\"\n",
    "    if len(result1) == 0 and len(result2) == 0:\n",
    "        result = \"same\"\n",
    "        return True,result\n",
    "\n",
    "    # if length is not the same, then they are definitely different bag of rows\n",
    "    status =0\n",
    "    if len(result1) != len(result2):\n",
    "        if len(result1)==0:\n",
    "            result = \"P result zero\"\n",
    "        elif len(result2)==0:\n",
    "            result = \"Q result zero\"\n",
    "        elif len(result1) > len(result2):\n",
    "            for res in result2:\n",
    "                if res in result1:\n",
    "                    status =1\n",
    "            if status ==1:\n",
    "                result = \"Partial Match\"\n",
    "            else:\n",
    "                result = \"P result greater\"\n",
    "                \n",
    "        elif len(result1) < len(result2):\n",
    "            for res in result1:\n",
    "                if res in result2:\n",
    "                    status =1\n",
    "            if status ==1:\n",
    "                result = \"Partial Match\"\n",
    "            else:   \n",
    "                result = \"Q result greater\"    \n",
    "        return False,result\n",
    "        \n",
    "\n",
    "    num_cols = len(result1[0])\n",
    "\n",
    "    # if the results do not have the same number of columns, they are different\n",
    "    if len(result2[0]) != num_cols:\n",
    "        result = \"column length different\"\n",
    "        return False,result\n",
    "\n",
    "    # unorder each row and compare whether the denotation is the same\n",
    "    # this can already find most pair of denotations that are different\n",
    "    if not quick_rej(result1, result2, order_matters):\n",
    "        count =0\n",
    "        for res in result2:\n",
    "                if res in result1:\n",
    "                    count =1\n",
    "        if count ==1:\n",
    "            result = \"Partial Match\"\n",
    "        else:\n",
    "            result = \"order or result different\"\n",
    "        return False,result\n",
    "\n",
    "    # the rest of the problem is in fact more complicated than one might think\n",
    "    # we want to find a permutation of column order and a permutation of row order,\n",
    "    # s.t. result_1 is the same as result_2\n",
    "    # we return true if we can find such column & row permutations\n",
    "    # and false if we cannot\n",
    "    tab1_sets_by_columns = [{row[i] for row in result1} for i in range(num_cols)]\n",
    "\n",
    "    # on a high level, we enumerate all possible column permutations that might make result_1 == result_2\n",
    "    # we decrease the size of the column permutation space by the function get_constraint_permutation\n",
    "    # if one of the permutation make result_1, result_2 equivalent, then they are equivalent\n",
    "    for perm in get_constraint_permutation(tab1_sets_by_columns, result2):\n",
    "        if len(perm) != len(set(perm)):\n",
    "            continue\n",
    "        if num_cols == 1:\n",
    "            result2_perm = result2\n",
    "        else:\n",
    "            result2_perm = [permute_tuple(element, perm) for element in result2]\n",
    "        if order_matters:\n",
    "            if result1 == result2_perm:\n",
    "                result =\"same\"\n",
    "                return True,result\n",
    "        else:\n",
    "            # in fact the first condition must hold if the second condition holds\n",
    "            # but the first is way more efficient implementation-wise\n",
    "            # and we use it to quickly reject impossible candidates\n",
    "            if set(result1) == set(result2_perm) and multiset_eq(result1, result2_perm):\n",
    "                result =\"same\"\n",
    "                return True,result\n",
    "    return False,result\n",
    "\n",
    "\n",
    "# def insert_data(db_name, data):\n",
    "#     # Connect to SQLite database\n",
    "#     conn = sqlite3.connect(f\"{db_name}.db\")\n",
    "#     cursor = conn.cursor()\n",
    "\n",
    "def quick_rej(result1, result2, order_matters):\n",
    "    s1 = [unorder_row(row) for row in result1]\n",
    "    s2 = [unorder_row(row) for row in result2]\n",
    "    if order_matters:\n",
    "        return s1 == s2\n",
    "    else:\n",
    "        return set(s1) == set(s2)\n",
    "\n",
    "def unorder_row(row):\n",
    "    return tuple(sorted(row, key=lambda x: str(x) + str(type(x))))\n",
    "\n",
    "def get_constraint_permutation(tab1_sets_by_columns, result2):\n",
    "    num_cols = len(result2[0])\n",
    "    perm_constraints = [{i for i in range(num_cols)} for _ in range(num_cols)]\n",
    "    if num_cols <= 3:\n",
    "        return product(*perm_constraints)\n",
    "\n",
    "    # we sample 20 rows and constrain the space of permutations\n",
    "    for _ in range(20):\n",
    "        random_tab2_row = random.choice(result2)\n",
    "\n",
    "        for tab1_col in range(num_cols):\n",
    "            for tab2_col in set(perm_constraints[tab1_col]):\n",
    "                if random_tab2_row[tab2_col] not in tab1_sets_by_columns[tab1_col]:\n",
    "                    perm_constraints[tab1_col].remove(tab2_col)\n",
    "    return product(*perm_constraints)\n",
    "\n",
    "def permute_tuple(element, perm):\n",
    "    assert len(element) == len(perm)\n",
    "    return tuple([element[i] for i in perm])\n",
    "\n",
    "def multiset_eq(l1, l2):\n",
    "    if len(l1) != len(l2):\n",
    "        return False\n",
    "    d = defaultdict(int)\n",
    "    for e in l1:\n",
    "        d[e] = d[e] + 1\n",
    "    for e in l2:\n",
    "        d[e] = d[e] - 1\n",
    "        if d[e] < 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# db_name = 'contracts_database'\n",
    "# create_db_and_table(db_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# with open(\"/home/askyourcorpus/owais_querycraft_experiments/QueryCraft-fork/input/datasets/synthetic_data.json\",\"r\") as file:\n",
    "#     data = json.load(file)\n",
    "#     for obj in data:\n",
    "#         insert_data(db_name, obj)\n",
    "# import csv\n",
    "# with open(\"/home/askyourcorpus/owais_querycraft_experiments/QueryCraft-fork/synthetic_data.csv\", mode='w', newline='') as file:\n",
    "#     # Create a writer object from csv module\n",
    "#     csv_writer = csv.writer(file)\n",
    "    \n",
    "#     # Add column headers\n",
    "#     csv_writer.writerow(data[0].keys())\n",
    "    \n",
    "#     # Add rows\n",
    "#     for row in data:\n",
    "#         csv_writer.writerow(row.values())\n",
    "\n",
    "\n",
    "def tokenize_sql_query(sql_query):\n",
    "    token_list = []\n",
    "    try:\n",
    "        for token in Parser(sql_query).tokens:\n",
    "            token_list.append(str(token.value))\n",
    "    except:\n",
    "        pass\n",
    "    return token_list\n",
    "\n",
    "\n",
    "dict_accuracy_overall = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba591d3-3c85-48e1-b029-472aa9dd5de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# codellama_codellama-34b-instruct_data.csv\n",
    "# deepseek-ai_deepseek-coder-33b-instruct_data.csv\n",
    "# ibm_granite-13b-instruct-v2_data.csv\n",
    "# ibm_granite-20b-code-instruct_data.csv\n",
    "# ibm_granite-34b-code-instruct_data.csv\n",
    "# ibm_granite-8b-code-instruct_data.csv\n",
    "# kaist-ai_prometheus-8x7b-v2_data.csv\n",
    "# meta-llama_llama-3-70b-instruct_data.csv\n",
    "# mistralai_mixtral-8x7b-instruct-v01_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b599b7ad-0f86-4560-bad6-dc80a237cf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_csv(\"../input/_dataset_v3/codellama_codellama-34b-instruct_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b47f7e-9447-4940-96ba-b718eeebce2d",
   "metadata": {},
   "source": [
    "# 1. codellama_34b_instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a7042e-5162-49c1-bdcb-e4f187c25c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/qc_csvs_previous/codellama_codellama-34b-instruct_data.csv\")\n",
    "df[\"predicted_query_toks\"] = df[\"generated query\"].apply(tokenize_sql_query).astype(str).replace(\",\",\" \")\n",
    "df[\"expected_query_toks\"] = df[\"expected query\"].apply(tokenize_sql_query).astype(str).replace(\",\",\" \")\n",
    "\n",
    "df['expected_sql_classification'] = df['expected query'].apply(lambda sql: get_category(sql))\n",
    "df['generated_sql_classification'] = df['generated query'].apply(lambda sql: get_category(sql))\n",
    "df = calculate_classification(df,)\n",
    "df = calculate_classification_new(df)\n",
    "\n",
    "df.to_csv(\"../output/inference_/codellama_codellama-34b-instruct_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ddad49-5321-474a-a2fd-e0153edf74c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_str = (\n",
    "    \"DRIVER={IBM DB2 ODBC DRIVER};\"\n",
    "    \"DATABASE=bludb;\"\n",
    "    \"HOSTNAME=ba99a9e6-d59e-4883-8fc0-d6a8c9f7a08f.c1ogj3sd0tgtu0lqde00.databases.appdomain.cloud;\"\n",
    "    \"PORT=31321;\"\n",
    "    \"PROTOCOL=TCPIP;\"\n",
    "    \"UID=csr11117;\"\n",
    "    \"PWD=609Np3exGwBzg1QI;\"\n",
    "    \"SECURITY=SSL;\"\n",
    ")\n",
    "\n",
    "\n",
    "conn = ibm_db.connect(conn_str, \"\", \"\")\n",
    "if conn:\n",
    "    print(\"Connected to the database.\")\n",
    "else:\n",
    "    print(\"Connection failed.\")\n",
    "\n",
    "    \n",
    "def isValidSQLdb2(sql, conn=conn):\n",
    "    try:\n",
    "        stmt = ibm_db.exec_immediate(conn, sql.replace(\"contracts\",\"contract.contract\").replace(\"function\",\"functions\").replace(\"created_on\",\"effective_date\",).upper())#.replace(\"contracts\",\"test\"))\n",
    "        result = []\n",
    "        row = ibm_db.fetch_assoc(stmt)\n",
    "        while row:\n",
    "            result.append(row)\n",
    "            row = ibm_db.fetch_assoc(stmt)\n",
    "        \n",
    "        for row in result:\n",
    "            print(row)\n",
    "    except:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b16cf0-2714-4855-a077-1080bd33612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_db.fetch_assoc(ibm_db.exec_immediate(conn,\"SELECT * from test.contract\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b252f6ff-ce35-4724-a432-198f8b6b7d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_db.fetch_assoc(ibm_db.exec_immediate(conn,\"SELECT * from contract.contract\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da66a875-a346-4430-a012-f438a4a8dff4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stmt = ibm_db.exec_immediate(conn, \"SELECT * from contract.contract\")\n",
    "result = ibm_db.fetch_assoc(stmt)\n",
    "\n",
    "\n",
    "# stmt = ibm_db.exec_immediate(conn, sql)\n",
    "# result = ibm_db.fetch_assoc(stmt)\n",
    "i=0\n",
    "while result:\n",
    "    print(result,i)\n",
    "    i=i+1\n",
    "    result = ibm_db.fetch_assoc(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bbf034-c348-4538-9272-e21dabc22815",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM CONTRACT.CONTRACT FETCH FIRST 1 ROW ONLY\"\n",
    "stmt = ibm_db.exec_immediate(conn, query)\n",
    "row = ibm_db.fetch_assoc(stmt)\n",
    "print(row.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fa417e-6761-4ddc-8ba1-ab729623594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['expected query'][1].upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1944c9b2-63c0-4076-8ab6-154c65f2a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = ibm_db.exec_immediate(conn, df['expected query'][1].replace(\"\\n\",\" \").upper())#.replace(\"contracts\",\"test\"))\n",
    "\n",
    "result = []\n",
    "row = ibm_db.fetch_assoc(stmt)\n",
    "while row:\n",
    "    result.append(row)\n",
    "    row = ibm_db.fetch_assoc(stmt)\n",
    "\n",
    "for row in result:\n",
    "    print(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b68af49-97f4-468d-b6d9-235241651576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibm_db\n",
    "\n",
    "query = \"SELECT COUNT(*) AS TOTAL_CONTRACTS FROM CONTRACT\"\n",
    "\n",
    "stmt = ibm_db.exec_immediate(conn, query)\n",
    "\n",
    "result = []\n",
    "row = ibm_db.fetch_assoc(stmt)\n",
    "while row:\n",
    "    result.append(row)\n",
    "    row = ibm_db.fetch_assoc(stmt)\n",
    "\n",
    "for row in result:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c35f9cb-e67c-4f4a-9d3a-24d95ceb37fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT COUNT(*) AS TOTAL_CONTRACTS, SUPPLIER FROM CONTRACT GROUP BY SUPPLIER\"\n",
    "isValidSQL(query, \"contracts_database.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7015a8fc-ab21-4a79-8e2b-c1bd0e4bb098",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.Series(df['expected query'].apply(isValidSQLdb2)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2e50f5-e0b3-4e6c-859d-ff61edb94316",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(df['generated query'].apply(isValidSQLdb2)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172f12a0-2460-4570-af00-bd312ba4219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['expected query'].apply(lambda sql: isValidSQL(sql, \"contracts_database.db\")).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f3fa27-0e67-4d2b-8939-1446d4700949",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['generated query'].apply(lambda sql: isValidSQL(sql, \"contracts_database.db\")).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad50220f-2c5e-4f4a-954b-4d29a052dfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = ibm_db.exec_immediate(conn, df['expected query'][0].replace(\"contracts\",\"contract.contract\").replace(\"function\",\"functions\").replace(\"created_on\",\"effective_date\",).upper())#.replace(\"contracts\",\"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe64420-bd77-4b9c-9a10-5f2525e6b044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df = df[df['expected_sql_valid']==True]\n",
    "grouped = df.groupby('expected_sql_classification')\n",
    "execution_accuracy = {}\n",
    "\n",
    "cat_df = pd.DataFrame(columns=[\"category\",\"Total evaluation records for category\",\"Total correct responses\",\"Execution accuracy %\"])\n",
    "for name, group in grouped:\n",
    "    cat_list=[]\n",
    "    total_true = group['evalScore'].sum()\n",
    "    total_records = len(group)\n",
    "    print(total_true,total_records,\"##\")\n",
    "    accuracy = total_true / total_records\n",
    "    execution_accuracy[name] = accuracy\n",
    "    cat_list.append(name)\n",
    "    cat_list.append(total_records)\n",
    "    cat_list.append(total_true)\n",
    "    cat_list.append(accuracy)\n",
    "    print(cat_list)\n",
    "    new_row_df = pd.DataFrame([cat_list], columns=cat_df.columns)\n",
    "    cat_df = pd.concat([cat_df, new_row_df], ignore_index=True)\n",
    "\n",
    "\n",
    "tot_list = []\n",
    "category = \"TOTAL\"\n",
    "total_eval_records = filtered_df.shape[0]\n",
    "evalScore_counts = df[df['evalScore'] == True]['evalScore'].value_counts()[0]\n",
    "exec_accuracy =  evalScore_counts/total_eval_records\n",
    "tot_list.append(category)\n",
    "tot_list.append(total_eval_records)\n",
    "tot_list.append(evalScore_counts)\n",
    "tot_list.append(exec_accuracy)\n",
    "new_row_df = pd.DataFrame([tot_list], columns=cat_df.columns)\n",
    "cat_df = pd.concat([cat_df, new_row_df], ignore_index=True)\n",
    "cat_df['Execution accuracy %'] =round(cat_df['Execution accuracy %']*100,2)\n",
    "cat_df.to_csv(\"../output/inference__v2/accumulated_accuracy/codellama_34b_instruct.csv\",index=False)\n",
    "\n",
    "\n",
    "df_codellama_34b_instruct = pd.read_csv(\"../output/inference__v2/accumulated_accuracy/codellama_34b_instruct.csv\")\n",
    "dict_accuracy_overall[\"codellama_34b_instruct\"] =  df_codellama_34b_instruct[df_codellama_34b_instruct[\"category\"]==\"TOTAL\"][\"Execution accuracy %\"].values[0]\n",
    "dict_accuracy_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e034eb1b-2683-4e9c-b45f-05777afad647",
   "metadata": {},
   "source": [
    "# 2. ibm_granite_34b_code_instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8f32ce-83c0-4f38-a00e-7ae0d4349b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/askyourcorpus/owais_querycraft_experiments/QueryCraft-fork/input/qc_csvs_previous/Answers_ibm_granite-34b-code-instruct_exEvaluator.csv\").rename(columns={\"Answers_ibm_granite-34b-code-instruct\":\"Predicted Query\",\"Expected\":\"Expected Query\"})\n",
    "df[\"predicted_query_toks\"] = df[\"Predicted Query\"].apply(tokenize_sql_query).astype(str).replace(\",\",\" \")\n",
    "df[\"expected_query_toks\"] = df[\"Expected Query\"].apply(tokenize_sql_query).astype(str).replace(\",\",\" \")\n",
    "\n",
    "df = calculate_classification(df,)\n",
    "df = calculate_classification_new(df)\n",
    "df = df.rename(columns={\"query\":\"Answers_ibm_granite-34b-code-instruct\"})#[[\"Question\",\"Entity\",\"Expected\",\"Answers_ibm_granite-34b-instruct\",\"query_toks\",\"count\",\"difficulty\",\"classification\",\"classification_new\"]]\n",
    "df.to_csv(\"../output/inference__v2/ibm_granite_34b_code_instruct.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a23ade6-d3f2-4f8e-a08e-2c9e0d42cb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01f3d54-d10a-4087-b7ff-8e42f730a31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['expected_sql_valid']==True]\n",
    "grouped = filtered_df.groupby('expected_sql_classification')\n",
    "execution_accuracy = {}\n",
    "\n",
    "cat_df = pd.DataFrame(columns=[\"category\",\"Total evaluation records for category\",\"Total correct responses\",\"Execution accuracy %\"])\n",
    "for name, group in grouped:\n",
    "    cat_list=[]\n",
    "    total_true = group['evalScore'].sum()\n",
    "    total_records = len(group)\n",
    "    print(total_true,total_records,\"##\")\n",
    "    accuracy = total_true / total_records\n",
    "    execution_accuracy[name] = accuracy\n",
    "    cat_list.append(name)\n",
    "    cat_list.append(total_records)\n",
    "    cat_list.append(total_true)\n",
    "    cat_list.append(accuracy)\n",
    "    print(cat_list)\n",
    "    new_row_df = pd.DataFrame([cat_list], columns=cat_df.columns)\n",
    "    cat_df = pd.concat([cat_df, new_row_df], ignore_index=True)\n",
    "\n",
    "\n",
    "tot_list = []\n",
    "category = \"TOTAL\"\n",
    "total_eval_records = filtered_df.shape[0]\n",
    "evalScore_counts = filtered_df[filtered_df['evalScore'] == True]['evalScore'].value_counts()[0]\n",
    "exec_accuracy =  evalScore_counts/total_eval_records\n",
    "tot_list.append(category)\n",
    "tot_list.append(total_eval_records)\n",
    "tot_list.append(evalScore_counts)\n",
    "tot_list.append(exec_accuracy)\n",
    "new_row_df = pd.DataFrame([tot_list], columns=cat_df.columns)\n",
    "cat_df = pd.concat([cat_df, new_row_df], ignore_index=True)\n",
    "cat_df['Execution accuracy %'] =round(cat_df['Execution accuracy %']*100,2)\n",
    "cat_df.to_csv(\"../output/inference__v2/accumulated_accuracy/ibm_granite_34b_code_instruct.csv\",index=False)\n",
    "\n",
    "\n",
    "df_ibm_granite_34b_code_instruct = pd.read_csv(\"../output/inference__v2/accumulated_accuracy/ibm_granite_34b_code_instruct.csv\")\n",
    "dict_accuracy_overall[\"ibm_granite_34b_code_instruct\"] =  df_ibm_granite_34b_code_instruct[df_ibm_granite_34b_code_instruct[\"category\"]==\"TOTAL\"][\"Execution accuracy %\"].values[0]\n",
    "dict_accuracy_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401acf7f-e335-403f-b129-8f1ff984fdf3",
   "metadata": {},
   "source": [
    "# 3. Deepseek_coder_33b_instruct_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963dc2d0-a81b-4173-bf8d-9090f759fb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/askyourcorpus/owais_querycraft_experiments/QueryCraft-fork/input/qc_csvs_previous/Answers_deepseek-ai_deepseek-coder-33b-instruct_exEvaluator.csv\").rename(columns={\"Answers_deepseek-ai_deepseek-coder-33b-instruct\":\"Predicted Query\",\"Expected\":\"Expected Query\"})\n",
    "df[\"predicted_query_toks\"] = df[\"Predicted Query\"].apply(tokenize_sql_query).astype(str).replace(\",\",\" \")\n",
    "df[\"expected_query_toks\"] = df[\"Expected Query\"].apply(tokenize_sql_query).astype(str).replace(\",\",\" \")\n",
    "\n",
    "df = calculate_classification(df,)\n",
    "df = calculate_classification_new(df)\n",
    "df = df.rename(columns={\"query\":\"Answers_deepseek-ai_deepseek-coder-33b-instruct\"})#[[\"Question\",\"Entity\",\"Expected\",\"Answers_ibm_granite-34b-instruct\",\"query_toks\",\"count\",\"difficulty\",\"classification\",\"classification_new\"]]\n",
    "df.to_csv(\"../output/inference__v2/deepseek-ai_deepseek-coder-33b-instruct.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fde3499-0d8a-4596-95a4-e7f3908a972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['expected_sql_valid']==True]\n",
    "grouped = filtered_df.groupby('expected_sql_classification')\n",
    "execution_accuracy = {}\n",
    "\n",
    "cat_df = pd.DataFrame(columns=[\"category\",\"Total evaluation records for category\",\"Total correct responses\",\"Execution accuracy %\"])\n",
    "for name, group in grouped:\n",
    "    cat_list=[]\n",
    "    total_true = group['evalScore'].sum()\n",
    "    total_records = len(group)\n",
    "    print(total_true,total_records,\"##\")\n",
    "    accuracy = total_true / total_records\n",
    "    execution_accuracy[name] = accuracy\n",
    "    cat_list.append(name)\n",
    "    cat_list.append(total_records)\n",
    "    cat_list.append(total_true)\n",
    "    cat_list.append(accuracy)\n",
    "    print(cat_list)\n",
    "    new_row_df = pd.DataFrame([cat_list], columns=cat_df.columns)\n",
    "    cat_df = pd.concat([cat_df, new_row_df], ignore_index=True)\n",
    "\n",
    "\n",
    "tot_list = []\n",
    "category = \"TOTAL\"\n",
    "total_eval_records = filtered_df.shape[0]\n",
    "evalScore_counts = filtered_df[filtered_df['evalScore'] == True]['evalScore'].value_counts()[0]\n",
    "exec_accuracy =  evalScore_counts/total_eval_records\n",
    "tot_list.append(category)\n",
    "tot_list.append(total_eval_records)\n",
    "tot_list.append(evalScore_counts)\n",
    "tot_list.append(exec_accuracy)\n",
    "new_row_df = pd.DataFrame([tot_list], columns=cat_df.columns)\n",
    "cat_df = pd.concat([cat_df, new_row_df], ignore_index=True)\n",
    "cat_df['Execution accuracy %'] =round(cat_df['Execution accuracy %']*100,2)\n",
    "cat_df.to_csv(\"../output/inference__v2/accumulated_accuracy/Deepseek_coder_33b_instruct_data.csv\",index=False)\n",
    "\n",
    "\n",
    "df_Deepseek_coder_33b_instruct_data = pd.read_csv(\"../output/inference__v2/accumulated_accuracy/Deepseek_coder_33b_instruct_data.csv\")\n",
    "dict_accuracy_overall[\"Deepseek_coder_33b_instruct_data\"] =  df_Deepseek_coder_33b_instruct_data[df_Deepseek_coder_33b_instruct_data[\"category\"]==\"TOTAL\"][\"Execution accuracy %\"].values[0]\n",
    "dict_accuracy_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f602720-c018-4407-9075-66ea85294d54",
   "metadata": {},
   "source": [
    "# 4. ibm_granite-13b-instruct-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82adb53e-0620-4033-84c5-8fd5dba4fbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/askyourcorpus/owais_querycraft_experiments/QueryCraft-fork/input/_dataset_v2/Answers_ibm_granite-13b-instruct-v2_exEvaluator.csv\",).rename(columns={\"Answers_ibm_granite-13b-instruct-v2\":\"Predicted Query\",\"Expected\":\"Expected Query\"})\n",
    "df[\"predicted_query_toks\"] = df[\"Predicted Query\"].apply(tokenize_sql_query).astype(str).replace(\",\",\" \")\n",
    "df[\"expected_query_toks\"] = df[\"Expected Query\"].apply(tokenize_sql_query).astype(str).replace(\",\",\" \")\n",
    "\n",
    "df = calculate_classification(df,)\n",
    "df = calculate_classification_new(df)\n",
    "df = df.rename(columns={\"query\":\"Answers_ibm_granite-13b-instruct-v2\"})#[[\"Question\",\"Entity\",\"Expected\",\"Answers_ibm_granite-13b-instruct-v2\",\"query_toks\",\"count\",\"difficulty\",\"classification\",\"classification_new\"]]\n",
    "df.to_csv(\"../output/inference__v2/ibm_granite-13b-instruct-v2.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea3f203-3041-4fe0-9f69-805acd0a622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['expected_sql_valid']==True]\n",
    "grouped = filtered_df.groupby('expected_sql_classification')\n",
    "execution_accuracy = {}\n",
    "\n",
    "cat_df = pd.DataFrame(columns=[\"category\",\"Total evaluation records for category\",\"Total correct responses\",\"Execution accuracy %\"])\n",
    "for name, group in grouped:\n",
    "    cat_list=[]\n",
    "    total_true = group['evalScore'].sum()\n",
    "    total_records = len(group)\n",
    "    print(total_true,total_records,\"##\")\n",
    "    accuracy = total_true / total_records\n",
    "    execution_accuracy[name] = accuracy\n",
    "    cat_list.append(name)\n",
    "    cat_list.append(total_records)\n",
    "    cat_list.append(total_true)\n",
    "    cat_list.append(accuracy)\n",
    "    print(cat_list)\n",
    "    new_row_df = pd.DataFrame([cat_list], columns=cat_df.columns)\n",
    "    cat_df = pd.concat([cat_df, new_row_df], ignore_index=True)\n",
    "\n",
    "\n",
    "tot_list = []\n",
    "category = \"TOTAL\"\n",
    "total_eval_records = filtered_df.shape[0]\n",
    "evalScore_counts = filtered_df[filtered_df['evalScore'] == True]['evalScore'].value_counts()[0]\n",
    "exec_accuracy =  evalScore_counts/total_eval_records\n",
    "tot_list.append(category)\n",
    "tot_list.append(total_eval_records)\n",
    "tot_list.append(evalScore_counts)\n",
    "tot_list.append(exec_accuracy)\n",
    "new_row_df = pd.DataFrame([tot_list], columns=cat_df.columns)\n",
    "cat_df = pd.concat([cat_df, new_row_df], ignore_index=True)\n",
    "cat_df['Execution accuracy %'] =round(cat_df['Execution accuracy %']*100,2)\n",
    "cat_df.to_csv(\"../output/inference__v2/accumulated_accuracy/ibm_granite-13b-instruct-v2.csv\",index=False)\n",
    "\n",
    "df_ibm_granite_13b_instruct_v2 = pd.read_csv(\"../output/inference__v2/accumulated_accuracy/ibm_granite-13b-instruct-v2.csv\")\n",
    "dict_accuracy_overall[\"ibm_granite-13b-instruct-v2\"] =  df_ibm_granite_13b_instruct_v2[df_ibm_granite_13b_instruct_v2[\"category\"]==\"TOTAL\"][\"Execution accuracy %\"].values[0]\n",
    "dict_accuracy_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dffda4d-cca2-4563-a9ba-c075deb35d89",
   "metadata": {},
   "source": [
    "# 5.ibm_granite-20b-code-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0d2c30-3a2d-4c6f-a977-644abac5f90a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/askyourcorpus/owais_querycraft_experiments/QueryCraft-fork/input/_dataset_v2/Answers_ibm_granite-20b-code-instruct_exEvaluator.csv\").rename(columns={\"Answers_ibm_granite-20b-code-instruct\":\"Predicted Query\",\"Expected\":\"Expected Query\"})\n",
    "df[\"predicted_query_toks\"] = df[\"Predicted Query\"].apply(tokenize_sql_query).astype(str).replace(\",\",\" \")\n",
    "df[\"expected_query_toks\"] = df[\"Expected Query\"].apply(tokenize_sql_query).astype(str).replace(\",\",\" \")\n",
    "\n",
    "df = calculate_classification(df,)\n",
    "df = calculate_classification_new(df)\n",
    "df = df.rename(columns={\"query\":\"Answers_ibm_granite-20b-code-instruct\"})#[[\"Question\",\"Entity\",\"Expected\",\"Answers_ibm_granite-20b-code-instruct\",\"query_toks\",\"count\",\"difficulty\",\"classification\",\"classification_new\"]]\n",
    "df.to_csv(\"../output/inference__v2/ibm_granite-20b-code-instruct.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c92ec5b-3c2c-417b-80ce-279dc70ff126",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['expected_sql_valid']==True]\n",
    "grouped = filtered_df.groupby('expected_sql_classification')\n",
    "execution_accuracy = {}\n",
    "\n",
    "cat_df = pd.DataFrame(columns=[\"category\",\"Total evaluation records for category\",\"Total correct responses\",\"Execution accuracy %\"])\n",
    "for name, group in grouped:\n",
    "    cat_list=[]\n",
    "    total_true = group['evalScore'].sum()\n",
    "    total_records = len(group)\n",
    "    print(total_true,total_records,\"##\")\n",
    "    accuracy = total_true / total_records\n",
    "    execution_accuracy[name] = accuracy\n",
    "    cat_list.append(name)\n",
    "    cat_list.append(total_records)\n",
    "    cat_list.append(total_true)\n",
    "    cat_list.append(accuracy)\n",
    "    print(cat_list)\n",
    "    new_row_df = pd.DataFrame([cat_list], columns=cat_df.columns)\n",
    "    cat_df = pd.concat([cat_df, new_row_df], ignore_index=True)\n",
    "\n",
    "\n",
    "tot_list = []\n",
    "category = \"TOTAL\"\n",
    "total_eval_records = filtered_df.shape[0]\n",
    "evalScore_counts = filtered_df[filtered_df['evalScore'] == True]['evalScore'].value_counts()[0]\n",
    "exec_accuracy =  evalScore_counts/total_eval_records\n",
    "tot_list.append(category)\n",
    "tot_list.append(total_eval_records)\n",
    "tot_list.append(evalScore_counts)\n",
    "tot_list.append(exec_accuracy)\n",
    "new_row_df = pd.DataFrame([tot_list], columns=cat_df.columns)\n",
    "cat_df = pd.concat([cat_df, new_row_df], ignore_index=True)\n",
    "cat_df['Execution accuracy %'] =round(cat_df['Execution accuracy %']*100,2)\n",
    "cat_df.to_csv(\"../output/inference__v2/accumulated_accuracy/ibm_granite-20b-code-instruct.csv\",index=False)\n",
    "\n",
    "\n",
    "df_ibm_granite_20b_code_instruct = pd.read_csv(\"../output/inference__v2/accumulated_accuracy/ibm_granite-20b-code-instruct.csv\")\n",
    "dict_accuracy_overall[\"ibm_granite-20b-code-instruct\"] =  df_ibm_granite_20b_code_instruct[df_ibm_granite_20b_code_instruct[\"category\"]==\"TOTAL\"][\"Execution accuracy %\"].values[0]\n",
    "dict_accuracy_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86af0174-8647-4fc9-884d-b80d253be38f",
   "metadata": {},
   "source": [
    "# 6. ibm_granite-8b-code-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432b61b7-498a-4d43-8382-d8e69329bc1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/askyourcorpus/owais_querycraft_experiments/QueryCraft-fork/input/_dataset_v2/Answers_ibm_granite-8b-code-instruct_exEvaluator.csv\").rename(columns={\"Answers_ibm_granite-8b-code-instruct\":\"Predicted Query\",\"Expected\":\"Expected Query\"})\n",
    "df[\"predicted_query_toks\"] = df[\"Predicted Query\"].apply(tokenize_sql_query).astype(str).replace(\",\",\" \")\n",
    "df[\"expected_query_toks\"] = df[\"Expected Query\"].apply(tokenize_sql_query).astype(str).replace(\",\",\" \")\n",
    "\n",
    "df = calculate_classification(df,)\n",
    "df = calculate_classification_new(df)\n",
    "df = df.rename(columns={\"query\":\"Answers_ibm_granite-8b-code-instruct\"})#[[\"Question\",\"Entity\",\"Expected\",\"Answers_ibm_granite-8b-code-instruct\",\"query_toks\",\"count\",\"difficulty\",\"classification\",\"classification_new\"]]\n",
    "df.to_csv(\"../output/inference__v2/ibm_granite-8b-code-instruct.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36027f36-9e76-425a-a162-b32aeb00cb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['expected_sql_valid']==True]\n",
    "grouped = filtered_df.groupby('expected_sql_classification')\n",
    "execution_accuracy = {}\n",
    "\n",
    "cat_df = pd.DataFrame(columns=[\"category\",\"Total evaluation records for category\",\"Total correct responses\",\"Execution accuracy %\"])\n",
    "for name, group in grouped:\n",
    "    cat_list=[]\n",
    "    total_true = group['evalScore'].sum()\n",
    "    total_records = len(group)\n",
    "    print(total_true,total_records,\"##\")\n",
    "    accuracy = total_true / total_records\n",
    "    execution_accuracy[name] = accuracy\n",
    "    cat_list.append(name)\n",
    "    cat_list.append(total_records)\n",
    "    cat_list.append(total_true)\n",
    "    cat_list.append(accuracy)\n",
    "    print(cat_list)\n",
    "    new_row_df = pd.DataFrame([cat_list], columns=cat_df.columns)\n",
    "    cat_df = pd.concat([cat_df, new_row_df], ignore_index=True)\n",
    "\n",
    "\n",
    "tot_list = []\n",
    "category = \"TOTAL\"\n",
    "total_eval_records = filtered_df.shape[0]\n",
    "evalScore_counts = filtered_df[filtered_df['evalScore'] == True]['evalScore'].value_counts()[0]\n",
    "exec_accuracy =  evalScore_counts/total_eval_records\n",
    "tot_list.append(category)\n",
    "tot_list.append(total_eval_records)\n",
    "tot_list.append(evalScore_counts)\n",
    "tot_list.append(exec_accuracy)\n",
    "new_row_df = pd.DataFrame([tot_list], columns=cat_df.columns)\n",
    "cat_df = pd.concat([cat_df, new_row_df], ignore_index=True)\n",
    "cat_df['Execution accuracy %'] =round(cat_df['Execution accuracy %']*100,2)\n",
    "cat_df.to_csv(\"../output/inference__v2/accumulated_accuracy/ibm_granite-8b-code-instruct.csv\",index=False)\n",
    "\n",
    "df_ibm_granite_8b_code_instruct = pd.read_csv(\"../output/inference__v2/accumulated_accuracy/ibm_granite-8b-code-instruct.csv\")\n",
    "dict_accuracy_overall[\"ibm_granite-8b-code-instruct\"] =  df_ibm_granite_8b_code_instruct[df_ibm_granite_8b_code_instruct[\"category\"]==\"TOTAL\"][\"Execution accuracy %\"].values[0]\n",
    "dict_accuracy_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa673d87-240a-4ea8-87c7-7c07dc52bc74",
   "metadata": {},
   "source": [
    "# 7.kaist-ai_prometheus-8x7b-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3278f5ae-7383-40e0-beb0-ab1d8f82eb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/askyourcorpus/owais_querycraft_experiments/QueryCraft-fork/input/_dataset_v2/Answers_kaist-ai_prometheus-8x7b-v2_exEvaluator.csv\").rename(columns={\"Answers_kaist-ai_prometheus-8x7b-v2\":\"Predicted Query\",\"Expected\":\"Expected Query\"})\n",
    "df[\"predicted_query_toks\"] = df[\"Predicted Query\"].apply(tokenize_sql_query).astype(str).replace(\",\",\" \")\n",
    "df[\"expected_query_toks\"] = df[\"Expected Query\"].apply(tokenize_sql_query).astype(str).replace(\",\",\" \")\n",
    "\n",
    "df = calculate_classification(df,)\n",
    "df = calculate_classification_new(df)\n",
    "df = df.rename(columns={\"query\":\"Answers_kaist-ai_prometheus-8x7b-v2\"})#[[\"Question\",\"Entity\",\"Expected\",\"Answers_ibm_granite-8b-code-instruct\",\"query_toks\",\"count\",\"difficulty\",\"classification\",\"classification_new\"]]\n",
    "df.to_csv(\"../output/inference__v2/kaist-ai_prometheus-8x7b-v2.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ccdceb-e877-4793-bc2c-18e7301f5a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['expected_sql_valid']==True]\n",
    "grouped = filtered_df.groupby('expected_sql_classification')\n",
    "execution_accuracy = {}\n",
    "\n",
    "cat_df = pd.DataFrame(columns=[\"category\",\"Total evaluation records for category\",\"Total correct responses\",\"Execution accuracy %\"])\n",
    "for name, group in grouped:\n",
    "    cat_list=[]\n",
    "    total_true = group['evalScore'].sum()\n",
    "    total_records = len(group)\n",
    "    print(total_true,total_records,\"##\")\n",
    "    accuracy = total_true / total_records\n",
    "    execution_accuracy[name] = accuracy\n",
    "    cat_list.append(name)\n",
    "    cat_list.append(total_records)\n",
    "    cat_list.append(total_true)\n",
    "    cat_list.append(accuracy)\n",
    "    print(cat_list)\n",
    "    new_row_df = pd.DataFrame([cat_list], columns=cat_df.columns)\n",
    "    cat_df = pd.concat([cat_df, new_row_df], ignore_index=True)\n",
    "\n",
    "\n",
    "tot_list = []\n",
    "category = \"TOTAL\"\n",
    "total_eval_records = filtered_df.shape[0]\n",
    "evalScore_counts = filtered_df[filtered_df['evalScore'] == True]['evalScore'].value_counts()[0]\n",
    "exec_accuracy =  evalScore_counts/total_eval_records\n",
    "tot_list.append(category)\n",
    "tot_list.append(total_eval_records)\n",
    "tot_list.append(evalScore_counts)\n",
    "tot_list.append(exec_accuracy)\n",
    "new_row_df = pd.DataFrame([tot_list], columns=cat_df.columns)\n",
    "cat_df = pd.concat([cat_df, new_row_df], ignore_index=True)\n",
    "cat_df['Execution accuracy %'] =round(cat_df['Execution accuracy %']*100,2)\n",
    "\n",
    "cat_df.to_csv(\"../output/inference__v2/accumulated_accuracy/kaist-ai_prometheus-8x7b-v2.csv\",index=False)\n",
    "\n",
    "df_kaist_ai_prometheus_8x7b_v2 = pd.read_csv(\"../output/inference__v2/accumulated_accuracy/kaist-ai_prometheus-8x7b-v2.csv\")\n",
    "dict_accuracy_overall[\"kaist-ai_prometheus-8x7b-v2\"] =  df_kaist_ai_prometheus_8x7b_v2[df_kaist_ai_prometheus_8x7b_v2[\"category\"]==\"TOTAL\"][\"Execution accuracy %\"].values[0]\n",
    "dict_accuracy_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35235731-c689-4b14-bcc3-6c276424b70a",
   "metadata": {},
   "source": [
    "# 8. meta-llama_llama-3-70b-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4786dfd6-f80d-4f19-8f20-e88a59edf9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/askyourcorpus/owais_querycraft_experiments/QueryCraft-fork/input/_dataset_v2/Answers_meta-llama_llama-3-70b-instruct_exEvaluator.csv\").rename(columns={\"Answers_meta-llama_llama-3-70b-instruct\":\"Predicted Query\",\"Expected\":\"Expected Query\"})\n",
    "df[\"predicted_query_toks\"] = df[\"Predicted Query\"].apply(tokenize_sql_query).astype(str).replace(\",\",\" \")\n",
    "df[\"expected_query_toks\"] = df[\"Expected Query\"].apply(tokenize_sql_query).astype(str).replace(\",\",\" \")\n",
    "\n",
    "df = calculate_classification(df,)\n",
    "df = calculate_classification_new(df)\n",
    "df = df.rename(columns={\"query\":\"Answers_meta-llama_llama-3-70b-instruct\"})#[[\"Question\",\"Entity\",\"Expected\",\"Answers_meta-llama_llama-3-70b-instruct\",\"query_toks\",\"count\",\"difficulty\",\"classification\",\"classification_new\"]]\n",
    "df.to_csv(\"../output/inference__v2/meta-llama_llama-3-70b-instruct.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeff6fe5-0ba0-469d-962b-29b97c548bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['expected_sql_valid']==True]\n",
    "grouped = filtered_df.groupby('expected_sql_classification')\n",
    "execution_accuracy = {}\n",
    "\n",
    "cat_df = pd.DataFrame(columns=[\"category\",\"Total evaluation records for category\",\"Total correct responses\",\"Execution accuracy %\"])\n",
    "for name, group in grouped:\n",
    "    cat_list=[]\n",
    "    total_true = group['evalScore'].sum()\n",
    "    total_records = len(group)\n",
    "    print(total_true,total_records,\"##\")\n",
    "    accuracy = total_true / total_records\n",
    "    execution_accuracy[name] = accuracy\n",
    "    cat_list.append(name)\n",
    "    cat_list.append(total_records)\n",
    "    cat_list.append(total_true)\n",
    "    cat_list.append(accuracy)\n",
    "    print(cat_list)\n",
    "    new_row_df = pd.DataFrame([cat_list], columns=cat_df.columns)\n",
    "    cat_df = pd.concat([cat_df, new_row_df], ignore_index=True)\n",
    "\n",
    "\n",
    "tot_list = []\n",
    "category = \"TOTAL\"\n",
    "total_eval_records = filtered_df.shape[0]\n",
    "evalScore_counts = filtered_df[filtered_df['evalScore'] == True]['evalScore'].value_counts()[0]\n",
    "exec_accuracy =  evalScore_counts/total_eval_records\n",
    "tot_list.append(category)\n",
    "tot_list.append(total_eval_records)\n",
    "tot_list.append(evalScore_counts)\n",
    "tot_list.append(exec_accuracy)\n",
    "new_row_df = pd.DataFrame([tot_list], columns=cat_df.columns)\n",
    "cat_df = pd.concat([cat_df, new_row_df], ignore_index=True)\n",
    "cat_df['Execution accuracy %'] =round(cat_df['Execution accuracy %']*100,2)\n",
    "cat_df.to_csv(\"../output/inference__v2/accumulated_accuracy/meta-llama_llama-3-70b-instruct.csv\",index=False)\n",
    "df_meta_llama_llama_3_70b_instruct = pd.read_csv(\"../output/inference__v2/accumulated_accuracy/meta-llama_llama-3-70b-instruct.csv\")\n",
    "dict_accuracy_overall[\"meta-llama_llama-3-70b-instruct\"] =  df_meta_llama_llama_3_70b_instruct[df_meta_llama_llama_3_70b_instruct[\"category\"]==\"TOTAL\"][\"Execution accuracy %\"].values[0]\n",
    "dict_accuracy_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b29951-92f5-4b1d-8952-6c8dd7d99599",
   "metadata": {},
   "source": [
    "# 9.mistralai_mixtral-8x7b-instruct-v01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3abd360-0b3d-410f-81fb-ab22d3e51d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/askyourcorpus/owais_querycraft_experiments/QueryCraft-fork/input/_dataset_v2/Answers_mistralai_mixtral-8x7b-instruct-v01_exEvaluator.csv\").rename(columns={\"Answers_mistralai_mixtral-8x7b-instruct-v01\":\"Predicted Query\",\"Expected\":\"Expected Query\"})\n",
    "df[\"predicted_query_toks\"] = df[\"Predicted Query\"].apply(tokenize_sql_query).astype(str).replace(\",\",\" \")\n",
    "df[\"expected_query_toks\"] = df[\"Expected Query\"].apply(tokenize_sql_query).astype(str).replace(\",\",\" \")\n",
    "\n",
    "df = calculate_classification(df,)\n",
    "df = calculate_classification_new(df)\n",
    "df = df.rename(columns={\"query\":\"Answers_mistralai_mixtral-8x7b-instruct-v01\"})#[[\"Question\",\"Entity\",\"Expected\",\"Answers_meta-llama_llama-3-70b-instruct\",\"query_toks\",\"count\",\"difficulty\",\"classification\",\"classification_new\"]]\n",
    "df.to_csv(\"../output/inference__v2/mistralai_mixtral-8x7b-instruct-v01.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1551096-f7ee-43df-9208-a5244621ff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['expected_sql_valid']==True]\n",
    "grouped = filtered_df.groupby('expected_sql_classification')\n",
    "execution_accuracy = {}\n",
    "\n",
    "cat_df = pd.DataFrame(columns=[\"category\",\"Total evaluation records for category\",\"Total correct responses\",\"Execution accuracy %\"])\n",
    "for name, group in grouped:\n",
    "    cat_list=[]\n",
    "    total_true = group['evalScore'].sum()\n",
    "    total_records = len(group)\n",
    "    print(total_true,total_records,\"##\")\n",
    "    accuracy = total_true / total_records\n",
    "    execution_accuracy[name] = accuracy\n",
    "    cat_list.append(name)\n",
    "    cat_list.append(total_records)\n",
    "    cat_list.append(total_true)\n",
    "    cat_list.append(accuracy)\n",
    "    print(cat_list)\n",
    "    new_row_df = pd.DataFrame([cat_list], columns=cat_df.columns)\n",
    "    cat_df = pd.concat([cat_df, new_row_df], ignore_index=True)\n",
    "\n",
    "\n",
    "tot_list = []\n",
    "category = \"TOTAL\"\n",
    "total_eval_records = filtered_df.shape[0]\n",
    "evalScore_counts = filtered_df[filtered_df['evalScore'] == True]['evalScore'].value_counts()[0]\n",
    "exec_accuracy =  evalScore_counts/total_eval_records\n",
    "tot_list.append(category)\n",
    "tot_list.append(total_eval_records)\n",
    "tot_list.append(evalScore_counts)\n",
    "tot_list.append(exec_accuracy)\n",
    "new_row_df = pd.DataFrame([tot_list], columns=cat_df.columns)\n",
    "cat_df = pd.concat([cat_df, new_row_df], ignore_index=True)\n",
    "cat_df['Execution accuracy %'] =round(cat_df['Execution accuracy %']*100,2)\n",
    "cat_df.to_csv(\"../output/inference__v2/accumulated_accuracy/mistralai_mixtral-8x7b-instruct-v01.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee6a785-9ceb-4ca6-8d20-2ee7a6c5e375",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mistralai_mixtral_8x7b_instruct_v01 = pd.read_csv(\"../output/inference__v2/accumulated_accuracy/mistralai_mixtral-8x7b-instruct-v01.csv\")\n",
    "dict_accuracy_overall[\"mistralai_mixtral_8x7b_instruct_v01\"] =  df_mistralai_mixtral_8x7b_instruct_v01[df_mistralai_mixtral_8x7b_instruct_v01[\"category\"]==\"TOTAL\"][\"Execution accuracy %\"].values[0]\n",
    "dict_accuracy_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d8607a-5002-4bd4-a182-7184ac965504",
   "metadata": {},
   "source": [
    "# 10. ibm_granite-34b-code-instruct_exEvaluator_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e701967-4457-416d-bb5a-8f6362c170c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/askyourcorpus/owais_querycraft_experiments/QueryCraft-fork/input/_dataset_v2/ibm_granite-34b-code-instruct_exEvaluator_agent.csv\").rename(columns={\"ibm_granite-34b-code-instruct\":\"Predicted Query\",\"Expected\":\"Expected Query\"})\n",
    "df[\"predicted_query_toks\"] = df[\"Predicted Query\"].astype(str).apply(tokenize_sql_query).replace(\",\",\" \")\n",
    "df[\"expected_query_toks\"] = df[\"Expected Query\"].apply(tokenize_sql_query).astype(str).replace(\",\",\" \")\n",
    "df[\"Predicted Query\"] = df[\"Predicted Query\"].astype(str)\n",
    "df = calculate_classification(df,)\n",
    "df = calculate_classification_new(df)\n",
    "df = df.rename(columns={\"query\":\"ibm_granite-34b-code-instruct_exEvaluator_agent\"})#[[\"Question\",\"Entity\",\"Expected\",\"Answers_meta-llama_llama-3-70b-instruct\",\"query_toks\",\"count\",\"difficulty\",\"classification\",\"classification_new\"]]\n",
    "df.to_csv(\"../output/inference__v2/ibm_granite-34b-code-instruct_exEvaluator_agent.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fea291-4dde-4e32-83d6-36e3f4f80b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['expected_sql_valid']==True]\n",
    "grouped = filtered_df.groupby('expected_sql_classification')\n",
    "execution_accuracy = {}\n",
    "\n",
    "cat_df = pd.DataFrame(columns=[\"category\",\"Total evaluation records for category\",\"Total correct responses\",\"Execution accuracy %\"])\n",
    "for name, group in grouped:\n",
    "    cat_list=[]\n",
    "    total_true = group['evalScore'].sum()\n",
    "    total_records = len(group)\n",
    "    print(total_true,total_records,\"##\")\n",
    "    accuracy = total_true / total_records\n",
    "    execution_accuracy[name] = accuracy\n",
    "    cat_list.append(name)\n",
    "    cat_list.append(total_records)\n",
    "    cat_list.append(total_true)\n",
    "    cat_list.append(accuracy)\n",
    "    print(cat_list)\n",
    "    new_row_df = pd.DataFrame([cat_list], columns=cat_df.columns)\n",
    "    cat_df = pd.concat([cat_df, new_row_df], ignore_index=True)\n",
    "\n",
    "\n",
    "tot_list = []\n",
    "category = \"TOTAL\"\n",
    "total_eval_records = filtered_df.shape[0]\n",
    "evalScore_counts = filtered_df[filtered_df['evalScore'] == True]['evalScore'].value_counts()[0]\n",
    "exec_accuracy =  evalScore_counts/total_eval_records\n",
    "tot_list.append(category)\n",
    "tot_list.append(total_eval_records)\n",
    "tot_list.append(evalScore_counts)\n",
    "tot_list.append(exec_accuracy)\n",
    "new_row_df = pd.DataFrame([tot_list], columns=cat_df.columns)\n",
    "cat_df = pd.concat([cat_df, new_row_df], ignore_index=True)\n",
    "cat_df['Execution accuracy %'] =round(cat_df['Execution accuracy %']*100,2)\n",
    "cat_df.to_csv(\"../output/inference__v2/accumulated_accuracy/ibm_granite-34b-code-instruct_exEvaluator_agent.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa1d55d-3080-4500-a8bc-e200a91d2de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ibm_granite_34b_code_instruct_exEvaluator_agent = pd.read_csv(\"../output/inference__v2/accumulated_accuracy/ibm_granite-34b-code-instruct_exEvaluator_agent.csv\")\n",
    "dict_accuracy_overall[\"ibm_granite_34b_code_instruct_exEvaluator_agent\"] =  df_ibm_granite_34b_code_instruct_exEvaluator_agent[df_ibm_granite_34b_code_instruct_exEvaluator_agent[\"category\"]==\"TOTAL\"][\"Execution accuracy %\"].values[0]\n",
    "dict_accuracy_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98574bf-3484-4966-be95-1d80bf272ab3",
   "metadata": {},
   "source": [
    "# 11. code llama-7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359108b4-fcaa-4a26-86bf-68b3492d21fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"/home/askyourcorpus/owais_querycraft_experiments/QueryCraft-fork/input/_dataset_v2/_code_llama-7b_inference.csv\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361a68ec-b4a8-46b5-8852-5f478eb7660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/askyourcorpus/owais_querycraft_experiments/QueryCraft-fork/input/_dataset_v2/_code_llama-7b_inference.csv\").rename(columns={\"model_op\":\"Predicted Query\",\"query\":\"Expected Query\"}).drop(columns=[\"Unnamed: 0\"])\n",
    "df[\"predicted_query_toks\"] = df[\"Predicted Query\"].astype(str).apply(tokenize_sql_query).replace(\",\",\" \")\n",
    "df[\"expected_query_toks\"] = df[\"Expected Query\"].apply(tokenize_sql_query).astype(str).replace(\",\",\" \")\n",
    "df[\"Predicted Query\"] = df[\"Predicted Query\"].astype(str)\n",
    "df = calculate_classification(df,)\n",
    "df = calculate_classification_new(df)\n",
    "df = df.rename(columns={\"query\":\"_code_llama_7b\"})#[[\"Question\",\"Entity\",\"Expected\",\"Answers_meta-llama_llama-3-70b-instruct\",\"query_toks\",\"count\",\"difficulty\",\"classification\",\"classification_new\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c82df8-c806-4c1f-9968-377324feb44f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check_database_schema(\"contracts_database.db\")\n",
    "df['expected_sql_valid'] = df['Expected Query'].apply(lambda sql: isValidSQL(sql, \"contracts_database.db\"))\n",
    "df['generated_sql_valid'] = df['Predicted Query'].apply(lambda sql: isValidSQL(sql, \"contracts_database.db\"))\n",
    "df['expected_sql_classification'] = df['Expected Query'].apply(lambda sql: get_category(sql))\n",
    "df['generated_sql_classification'] = df['Predicted Query'].apply(lambda sql: get_category(sql))\n",
    "results = []\n",
    "for index, row in df.iterrows():\n",
    "    evalScore, value, error, result = formaterAndCaller_sqlite(row, \"contracts_database.db\", \"Expected Query\", \"Predicted Query\")\n",
    "    df.at[index, 'evalScore'] = evalScore\n",
    "    df.at[index, 'evalScorePostProcessing'] = value\n",
    "    df.at[index, 'error_type'] = error\n",
    "    df.at[index, 'result'] = result\n",
    "    results.append(evalScore)\n",
    "\n",
    "df['evalScore'] = results\n",
    "df.to_csv(\"../output/inference__v2/_code_llama_7b.csv\",index=False)\n",
    "EXAccuracy = sum(results) / len(results) if results else 0\n",
    "logging.info(f\"EX Accuracy for Predicted Query: {EXAccuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1441da7-f13b-4a1f-88fb-0f71589b8d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870b0998-51fe-4b5a-a551-4be699f6a387",
   "metadata": {},
   "outputs": [],
   "source": [
    "df#.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab7efcd-da9c-4bd5-aba3-a8f90ef3e33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['expected_sql_valid']==True]\n",
    "grouped = filtered_df.groupby('expected_sql_classification')\n",
    "execution_accuracy = {}\n",
    "\n",
    "cat_df = pd.DataFrame(columns=[\"category\",\"Total evaluation records for category\",\"Total correct responses\",\"Execution accuracy %\"])\n",
    "for name, group in grouped:\n",
    "    cat_list=[]\n",
    "    total_true = group['evalScore'].sum()\n",
    "    total_records = len(group)\n",
    "    print(total_true,total_records,\"##\")\n",
    "    accuracy = total_true / total_records\n",
    "    execution_accuracy[name] = accuracy\n",
    "    cat_list.append(name)\n",
    "    cat_list.append(total_records)\n",
    "    cat_list.append(total_true)\n",
    "    cat_list.append(accuracy)\n",
    "    print(cat_list)\n",
    "    new_row_df = pd.DataFrame([cat_list], columns=cat_df.columns)\n",
    "    cat_df = pd.concat([cat_df, new_row_df], ignore_index=True)\n",
    "\n",
    "\n",
    "tot_list = []\n",
    "category = \"TOTAL\"\n",
    "total_eval_records = filtered_df.shape[0]\n",
    "evalScore_counts = filtered_df[filtered_df['evalScore'] == True]['evalScore'].value_counts()[0]\n",
    "exec_accuracy =  evalScore_counts/total_eval_records\n",
    "tot_list.append(category)\n",
    "tot_list.append(total_eval_records)\n",
    "tot_list.append(evalScore_counts)\n",
    "tot_list.append(exec_accuracy)\n",
    "new_row_df = pd.DataFrame([tot_list], columns=cat_df.columns)\n",
    "cat_df = pd.concat([cat_df, new_row_df], ignore_index=True)\n",
    "cat_df['Execution accuracy %'] =round(cat_df['Execution accuracy %']*100,2)\n",
    "cat_df.to_csv(\"../output/inference__v2/accumulated_accuracy/_code_llama_7b.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5977c2ba-cc89-43e9-9b91-86e146bb26aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df__code_llama_7b = pd.read_csv(\"../output/inference__v2/accumulated_accuracy/_code_llama_7b.csv\")\n",
    "dict_accuracy_overall[\"_code_llama_7b\"] =  df__code_llama_7b[df__code_llama_7b[\"category\"]==\"TOTAL\"][\"Execution accuracy %\"].values[0]\n",
    "dict_accuracy_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f09a7d0-7d15-49f0-9d88-026d220e6e7e",
   "metadata": {},
   "source": [
    "# 12. Granite-8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b43c08-a20d-4880-9ba7-8f0e84f162d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/askyourcorpus/owais_querycraft_experiments/QueryCraft-fork/input/_dataset_v2/_granite_8b_inference.csv\").rename(columns={\"model_op\":\"Predicted Query\",\"query\":\"Expected Query\"}).drop(columns=[\"Unnamed: 0\"])\n",
    "df[\"predicted_query_toks\"] = df[\"Predicted Query\"].astype(str).apply(tokenize_sql_query).replace(\",\",\" \")\n",
    "df[\"expected_query_toks\"] = df[\"Expected Query\"].apply(tokenize_sql_query).astype(str).replace(\",\",\" \")\n",
    "df[\"Predicted Query\"] = df[\"Predicted Query\"].astype(str)\n",
    "df = calculate_classification(df,)\n",
    "df = calculate_classification_new(df)\n",
    "df = df.rename(columns={\"query\":\"_granite_8b_inference\"})#[[\"Question\",\"Entity\",\"Expected\",\"Answers_meta-llama_llama-3-70b-instruct\",\"query_toks\",\"count\",\"difficulty\",\"classification\",\"classification_new\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6de55a-4bd8-4547-8ab0-6e730c1438e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check_database_schema(\"contracts_database.db\")\n",
    "df['expected_sql_valid'] = df['Expected Query'].apply(lambda sql: isValidSQL(sql, \"contracts_database.db\"))\n",
    "df['generated_sql_valid'] = df['Predicted Query'].apply(lambda sql: isValidSQL(sql, \"contracts_database.db\"))\n",
    "df['expected_sql_classification'] = df['Expected Query'].apply(lambda sql: get_category(sql))\n",
    "df['generated_sql_classification'] = df['Predicted Query'].apply(lambda sql: get_category(sql))\n",
    "results = []\n",
    "for index, row in df.iterrows():\n",
    "    evalScore, value, error, result = formaterAndCaller_sqlite(row, \"contracts_database.db\", \"Expected Query\", \"Predicted Query\")\n",
    "    df.at[index, 'evalScore'] = evalScore\n",
    "    df.at[index, 'evalScorePostProcessing'] = value\n",
    "    df.at[index, 'error_type'] = error\n",
    "    df.at[index, 'result'] = result\n",
    "    results.append(evalScore)\n",
    "\n",
    "df['evalScore'] = results\n",
    "df.to_csv(\"../output/inference__v2/_granite_8b_inference.csv\",index=False)\n",
    "EXAccuracy = sum(results) / len(results) if results else 0\n",
    "logging.info(f\"EX Accuracy for Predicted Query: {EXAccuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fb5be0-3643-4388-a0cf-0964b54950be",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['expected_sql_valid']==True]\n",
    "grouped = filtered_df.groupby('expected_sql_classification')\n",
    "execution_accuracy = {}\n",
    "\n",
    "cat_df = pd.DataFrame(columns=[\"category\",\"Total evaluation records for category\",\"Total correct responses\",\"Execution accuracy %\"])\n",
    "for name, group in grouped:\n",
    "    cat_list=[]\n",
    "    total_true = group['evalScore'].sum()\n",
    "    total_records = len(group)\n",
    "    print(total_true,total_records,\"##\")\n",
    "    accuracy = total_true / total_records\n",
    "    execution_accuracy[name] = accuracy\n",
    "    cat_list.append(name)\n",
    "    cat_list.append(total_records)\n",
    "    cat_list.append(total_true)\n",
    "    cat_list.append(accuracy)\n",
    "    print(cat_list)\n",
    "    new_row_df = pd.DataFrame([cat_list], columns=cat_df.columns)\n",
    "    cat_df = pd.concat([cat_df, new_row_df], ignore_index=True)\n",
    "\n",
    "\n",
    "tot_list = []\n",
    "category = \"TOTAL\"\n",
    "total_eval_records = filtered_df.shape[0]\n",
    "evalScore_counts = filtered_df[filtered_df['evalScore'] == True]['evalScore'].value_counts()[0]\n",
    "exec_accuracy =  evalScore_counts/total_eval_records\n",
    "tot_list.append(category)\n",
    "tot_list.append(total_eval_records)\n",
    "tot_list.append(evalScore_counts)\n",
    "tot_list.append(exec_accuracy)\n",
    "new_row_df = pd.DataFrame([tot_list], columns=cat_df.columns)\n",
    "cat_df = pd.concat([cat_df, new_row_df], ignore_index=True)\n",
    "cat_df['Execution accuracy %'] =round(cat_df['Execution accuracy %']*100,2)\n",
    "cat_df.to_csv(\"../output/inference__v2/accumulated_accuracy/_granite_8b_inference.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a13469-ea36-4fd0-a7c2-d32513697713",
   "metadata": {},
   "outputs": [],
   "source": [
    "df__granite_8b_inference = pd.read_csv(\"../output/inference__v2/accumulated_accuracy/_granite_8b_inference.csv\")\n",
    "dict_accuracy_overall[\"_granite_8b_inference\"] =  df__granite_8b_inference[df__granite_8b_inference[\"category\"]==\"TOTAL\"][\"Execution accuracy %\"].values[0]\n",
    "dict_accuracy_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c357f22-1c12-45d4-bc90-502533014f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(12, 6))\n",
    "ax[0].hist(df[\"Expected count\"], bins=20)\n",
    "ax[0].set_xlabel('Token Length')\n",
    "ax[0].set_ylabel('Frequency')\n",
    "ax[0].set_title('Expected SQL Query Token Length Frequency')\n",
    "\n",
    "ax[1].hist(df[\"Predicted count\"], bins=20)\n",
    "ax[1].set_xlabel('Token Length')\n",
    "ax[1].set_ylabel('Frequency')\n",
    "ax[1].set_title('Predicted SQL Query Token Length Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc2c67b-776e-409c-a074-59af95d3175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# context_data_option = st.selectbox(\n",
    "# 'Select a input data source: ',\n",
    "#             ('codellama-34b-instruct','ibm_granite-34b-code-instruct',\n",
    "#              'deepseek-ai_deepseek-coder-33b-instruct','ibm_granite-13b-instruct-v2',\n",
    "#               'ibm_granite-20b-code-instruct','ibm_granite-8b-code-instruct' ,\n",
    "#               'kaist-ai_prometheus-8x7b-v2','meta-llama_llama-3-70b-instruct',\n",
    "#               'mistralai_mixtral-8x7b-instruct-v01'\n",
    "#               ),index=0)\n",
    "\n",
    "\n",
    "# dict_mapping =  {\n",
    "#     'codellama-34b-instruct': \"/home/askyourcorpus/owais_querycraft_experiments/QueryCraft-fork/output/inference_/codellama_34b_instruct.csv\",\n",
    "#     'ibm_granite-34b-code-instruct': \"/home/askyourcorpus/owais_querycraft_experiments/QueryCraft-fork/output/inference_/ibm_granite_34b_code_instruct.csv\",\n",
    "#     'deepseek-ai_deepseek-coder-33b-instruct': \"/home/askyourcorpus/owais_querycraft_experiments/QueryCraft-fork/output/inference_/deepseek-ai_deepseek-coder-33b-instruct.csv\",\n",
    "#     'ibm_granite-13b-instruct-v2': \"/home/askyourcorpus/owais_querycraft_experiments/QueryCraft-fork/output/inference_/ibm_granite-13b-instruct-v2.csv\",\n",
    "#     'ibm_granite-20b-code-instruct': \"/home/askyourcorpus/owais_querycraft_experiments/QueryCraft-fork/output/inference_/ibm_granite-20b-code-instruct.csv\",\n",
    "#     'ibm_granite-8b-code-instruct': \"/home/askyourcorpus/owais_querycraft_experiments/QueryCraft-fork/output/inference_/ibm_granite-8b-code-instruct.csv\",\n",
    "#     'kaist-ai_prometheus-8x7b-v2': \"/home/askyourcorpus/owais_querycraft_experiments/QueryCraft-fork/output/inference_/kaist-ai_prometheus-8x7b-v2.csv\",\n",
    "#     'meta-llama_llama-3-70b-instruct': \"/home/askyourcorpus/owais_querycraft_experiments/QueryCraft-fork/output/inference_/meta-llama_llama-3-70b-instruct.csv\",\n",
    "#     'mistralai_mixtral-8x7b-instruct-v01': \"/home/askyourcorpus/owais_querycraft_experiments/QueryCraft-fork/output/inference_/mistralai_mixtral-8x7b-instruct-v01.csv\"\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2739833e-08f5-4704-8fa8-14db4470560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../output/inference__v2/accumulated_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72839f1-668a-49ac-8f17-3e4068b32cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40d9c0c-1468-4621-a1a3-98f0baecb7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_accuracy_overall = {}\n",
    "\n",
    "df_codellama_34b_instruct = pd.read_csv(\"../output/inference__v2/accumulated_accuracy/codellama_34b_instruct.csv\")\n",
    "dict_accuracy_overall[\"codellama_34b_instruct\"] =  df_codellama_34b_instruct[df_codellama_34b_instruct[\"category\"]==\"TOTAL\"][\"Execution accuracy %\"].values[0]\n",
    "\n",
    "df_ibm_granite_34b_code_instruct = pd.read_csv(\"../output/inference__v2/accumulated_accuracy/ibm_granite_34b_code_instruct.csv\")\n",
    "dict_accuracy_overall[\"ibm_granite_34b_code_instruct\"] =  df_ibm_granite_34b_code_instruct[df_ibm_granite_34b_code_instruct[\"category\"]==\"TOTAL\"][\"Execution accuracy %\"].values[0]\n",
    "\n",
    "\n",
    "df_Deepseek_coder_33b_instruct_data = pd.read_csv(\"../output/inference__v2/accumulated_accuracy/Deepseek_coder_33b_instruct_data.csv\")\n",
    "dict_accuracy_overall[\"Deepseek_coder_33b_instruct_data\"] =  df_Deepseek_coder_33b_instruct_data[df_Deepseek_coder_33b_instruct_data[\"category\"]==\"TOTAL\"][\"Execution accuracy %\"].values[0]\n",
    "dict_accuracy_overall\n",
    "\n",
    "\n",
    "df_ibm_granite_13b_instruct_v2 = pd.read_csv(\"../output/inference__v2/accumulated_accuracy/ibm_granite-13b-instruct-v2.csv\")\n",
    "dict_accuracy_overall[\"ibm_granite-13b-instruct-v2\"] =  df_ibm_granite_13b_instruct_v2[df_ibm_granite_13b_instruct_v2[\"category\"]==\"TOTAL\"][\"Execution accuracy %\"].values[0]\n",
    "\n",
    "\n",
    "df_ibm_granite_20b_code_instruct = pd.read_csv(\"../output/inference__v2/accumulated_accuracy/ibm_granite-20b-code-instruct.csv\")\n",
    "dict_accuracy_overall[\"ibm_granite-20b-code-instruct\"] =  df_ibm_granite_20b_code_instruct[df_ibm_granite_20b_code_instruct[\"category\"]==\"TOTAL\"][\"Execution accuracy %\"].values[0]\n",
    "\n",
    "\n",
    "df_kaist_ai_prometheus_8x7b_v2 = pd.read_csv(\"../output/inference__v2/accumulated_accuracy/kaist-ai_prometheus-8x7b-v2.csv\")\n",
    "dict_accuracy_overall[\"kaist-ai_prometheus-8x7b-v2\"] =  df_kaist_ai_prometheus_8x7b_v2[df_kaist_ai_prometheus_8x7b_v2[\"category\"]==\"TOTAL\"][\"Execution accuracy %\"].values[0]\n",
    "\n",
    "\n",
    "df_ibm_granite_8b_code_instruct = pd.read_csv(\"../output/inference__v2/accumulated_accuracy/ibm_granite-8b-code-instruct.csv\")\n",
    "dict_accuracy_overall[\"ibm_granite-8b-code-instruct\"] =  df_ibm_granite_8b_code_instruct[df_ibm_granite_8b_code_instruct[\"category\"]==\"TOTAL\"][\"Execution accuracy %\"].values[0]\n",
    "\n",
    "\n",
    "df_meta_llama_llama_3_70b_instruct = pd.read_csv(\"../output/inference__v2/accumulated_accuracy/meta-llama_llama-3-70b-instruct.csv\")\n",
    "dict_accuracy_overall[\"meta-llama_llama-3-70b-instruct\"] =  df_meta_llama_llama_3_70b_instruct[df_meta_llama_llama_3_70b_instruct[\"category\"]==\"TOTAL\"][\"Execution accuracy %\"].values[0]\n",
    "\n",
    "\n",
    "\n",
    "df_mistralai_mixtral_8x7b_instruct_v01 = pd.read_csv(\"../output/inference__v2/accumulated_accuracy/mistralai_mixtral-8x7b-instruct-v01.csv\")\n",
    "dict_accuracy_overall[\"mistralai_mixtral_8x7b_instruct_v01\"] =  df_mistralai_mixtral_8x7b_instruct_v01[df_mistralai_mixtral_8x7b_instruct_v01[\"category\"]==\"TOTAL\"][\"Execution accuracy %\"].values[0]\n",
    "\n",
    "\n",
    "df_ibm_granite_34b_code_instruct_exEvaluator_agent = pd.read_csv(\"../output/inference__v2/accumulated_accuracy/ibm_granite-34b-code-instruct_exEvaluator_agent.csv\")\n",
    "dict_accuracy_overall[\"ibm_granite_34b_code_instruct_exEvaluator_agent\"] =  df_ibm_granite_34b_code_instruct_exEvaluator_agent[df_ibm_granite_34b_code_instruct_exEvaluator_agent[\"category\"]==\"TOTAL\"][\"Execution accuracy %\"].values[0]\n",
    "\n",
    "\n",
    "df__code_llama_7b = pd.read_csv(\"../output/inference__v2/accumulated_accuracy/_code_llama_7b.csv\")\n",
    "dict_accuracy_overall[\"_code_llama_7b\"] =  df__code_llama_7b[df__code_llama_7b[\"category\"]==\"TOTAL\"][\"Execution accuracy %\"].values[0]\n",
    "\n",
    "\n",
    "df__granite_8b_inference = pd.read_csv(\"../output/inference__v2/accumulated_accuracy/_granite_8b_inference.csv\")\n",
    "dict_accuracy_overall[\"_granite_8b_inference\"] =  df__granite_8b_inference[df__granite_8b_inference[\"category\"]==\"TOTAL\"][\"Execution accuracy %\"].values[0]\n",
    "\n",
    "dict_accuracy_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa22ea1-7eac-45bd-8567-7ec5bc08aced",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_models = dict(sorted(dict_accuracy_overall.items(), key=lambda item: item[1]))\n",
    "\n",
    "sorted_model_names = list(sorted_models.keys())\n",
    "sorted_scores = list(sorted_models.values())\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "bars = plt.barh(sorted_model_names, sorted_scores, color='skyblue')\n",
    "\n",
    "for bar in bars:\n",
    "    plt.text(bar.get_width() + 0.5, bar.get_y() + bar.get_height() / 2, f'{bar.get_width():.2f}', \n",
    "             va='center', ha='left', fontsize=10)\n",
    "\n",
    "plt.xlabel('Scores', fontsize=14)\n",
    "plt.ylabel('Model Names', fontsize=14)\n",
    "plt.title('Comparison of Model Scores', fontsize=16)\n",
    "plt.grid(axis='x')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759118a2-96d2-4ac9-af7e-94500c35add7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
