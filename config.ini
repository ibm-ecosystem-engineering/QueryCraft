[DataIngestion]
# Enter the values for you database connection. This can be found in DB2's Service Credentials from the tooling. 
dsn_database = bludb
dsn_uid      = bvl11116
dsn_pwd      = ycoKedymqdKc7nxj
dsn_hostname = b1bc1829-6f45-4cd4-bef4-10cf081900bf.c1ogj3sd0tgtu0lqde00.databases.appdomain.cloud
dsn_port     = 32304
dsn_protocol = TCPIP
dsn_driver   = IBM DB2 ODBC DRIVER
#delimiter of  input file
delimiter = ,


[Finetune]
precision = 32
#Max context length
tokenizeMaxLength = 512
#LoRA hyperparameters rank, alpha and dropout
LoRA_r = 64
LoRA_alpha = 32
LoRA_dropout=0.1
#LoRA_taskType = "CAUSAL_LM"
#Batch Size
batch_size = 16
#In case of gradient accumulation, per device train batch size
per_device_train_batch_size = 1
#Select target modules for LoRA, either attention_linear_layers or all_linear_layers
target_modules = attention_linear_layers
#Number of epochs
num_train_epochs = 1
#Prompt file path to be used
#prompt_path =input/prompts/codellama_model.txt

[Inference] 
watsonx_url = https://us-south.ml.cloud.ibm.com
watsonx_apikey = 
watsonx_projectID = 


[logs]
#Path to logs folder, all log files would be created in this path
log_folder = output/logs/


[EXEvaluator]
#Unique identifier of your experiment run. The name is expected to be in following format "YOURINDETIFIER_ModelName_Date"]
EXP = exp_codellama-13b_spider_0412
#The output of the inference pipeline or any file on which you want to get an execution accuracy score
input_dataset = output/inference/exp_codellama-13b_spider_0412.csv

[QueryCorrection]
# The query_correction attribute is set to either 0 or 1, determining whether this module will be executed. By default, it's set to 1; if changed to 0, it indicates that the module will not be activated.
query_correction = 1



[QueryAnalysisDashboard]
text2sql_exp_file = output/result/text2sql_exp_results.csv
# The output file of token length which uses some examples of the open-source dataset
token_data_file = input/datasets/token_len_SQLModel.csv
# This image shows the spider benchmark which is available at their site
benchmark_image = output/benchmark/spider_benchmark.png
# combination of open source dataset file
input_dataset_file = input/datasets/spiderTrain_BIRDTrain_BIRDDev_CoSQLTran_CoSQLDev_SparcTrain_SparcDev_KaggleDBQA_withSource.csv
# Selected columns to create the CSV file for all experiments
selected_columns = Base_Model, Evaluation_set, Ex-accuracy, PP-Ex-accuracy, R, precision, Training_Set, LORA_Alpha, LORA_Dropout, Finetune_Strategy, Target_Modules, Task_Type, Epoch, Learning_Rate, Loss, Eval_Loss, Eval_Runtime, Eval Samples/Second, Eval Steps/Second, Logging_Steps, Max_Steps
