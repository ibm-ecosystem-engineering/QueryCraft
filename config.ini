[Default]
#This is the path to the folder where you have downloaded the repository
#home_dir = /home/jovyan/<YourWorkingDirectoryName>/QueryCraft-The-SuperKnowa-SQL-Sculptor/
home_dir = /home/jovyan/test_ak/QueryCraft-The-SuperKnowa-SQL-Sculptor/

[ContextRetriever]
#Relative path to the folder containing database dump in .sqlite format.
input_database_folder=input/spider/database/
#Relative path to the csv file with columns question, query, and db_id
input_data_file=input/datasets/spider.csv
#Name of the output file generated on running context_retriever.py
output_file = spiderWithContext

[Finetune]
#Unique identifier of your experiment run. The name is expected to be in following format "YOURINDETIFIER_ModelName_Date"]
#EXP = exp_CodeLlama-7b-Instruct-hf_16Feb_spider
#Relative path to the training dataset, we expect a CSV file with the following columns: db_id, question, query, context
trainDataset  = input/datasets/spiderWithContext.csv
#trainDataset = input/datasets/kaggleWithContext.csv
#Base model that you want to finetune
base_model = codellama/CodeLlama-7b-Instruct-hf
#Currently we only support PEFT-LORA finetuning
#finetuningMethod = LORA
#Select the floating point precision from either 32 or 8 bit
precision = 8
#Max context length
tokenizeMaxLength = 512
#LoRA hyperparameters rank, alpha and dropout
LoRA_r = 64
LoRA_alpha = 32
LoRA_dropout=0.1
#Batch Size
batch_size = 16
#In case of gradient accumulation, per device train batch size
per_device_train_batch_size = 1
#Select target modules for LoRA, either attention_linear_layers or all_linear_layers
target_modules = attention_linear_layers
#Number of epochs
num_train_epochs = 1
#Prompt file path to be used
#prompt_path =input/prompts/codellama_model.txt

[Inference] 
#Unique identifier of your experiment run. The name is expected to be in following format "YOURINDETIFIER_ModelName_Date"]
EXP = exp_CodeLlama-7b-Instruct-hf_16Feb_spider
#File path to data to be used for inference we expect a CSV file with the following columns: db_id, question, context
ip_dataset = input/datasets/spiderWithContext.csv
#ip_dataset = input/datasets/kaggleWithContext.csv
#Base model with which you want to draw inference
base_model = codellama/CodeLlama-7b-Instruct-hf
# Do you want to merge adapter weights with the base model, Y or N
#load_finetuned_model = Y
load_finetuned_model = N
# Path to the finetuned adapter weights. Use a similar format YOURINDETIFIER_ModelName_Date
finetuned_model = output/model/exp_CodeLlama-7b-Instruct-hf_16Feb_spider

[logs]
#Path to logs folder, all log files would be created in this path
log_folder = output/logs/


[EXEvaluator]
#Unique identifier of your experiment run. The name is expected to be in following format "YOURINDETIFIER_ModelName_Date"]
EXP = exp_CodeLlama-7b-Instruct-hf_16Feb_spider
#The output of the inference pipeline or any file on which you want to get an execution accuracy score
input_dataset = output/inference/exp_CodeLlama-7b-Instruct-hf_16Feb_spider.csv


[QueryAnalysisDashboard]
#Unique identifier of your experiment run. The name is expected to be in following format "YOURINDETIFIER_ModelName_Date"]
EXP = exp_CodeLlama-7b-Instruct-hf_16Feb_spider
#The output folder of the EXEvaluator pipeline or any file on which you want to get an execution accuracy score
folder_name =output/evalResults/
#The output file of all experiment logs consolidates results to showcase the experiment value
text2sql_exp_file = output/result/text2sql_exp_results.csv
# The output file of token length which uses some examples of the open-source dataset
token_data_file = input/datasets/token_len_SQLModel.csv
# This image shows the spider benchmark which is available at their site
benchmark_image = output/benchmark/spider_benchmark.png
# combination of open source dataset file
input_dataset_file = input/datasets/spiderTrain_BIRDTrain_BIRDDev_CoSQLTran_CoSQLDev_SparcTrain_SparcDev_KaggleDBQA_withSource.csv
# Selected columns to create the CSV file for all experiments
selected_columns = Base_Model, Evaluation_set, Ex-accuracy, PP-Ex-accuracy, R, precision, Training_Set, LORA_Alpha, LORA_Dropout, Finetune_Strategy, Target_Modules, Task_Type, Epoch, Learning_Rate, Loss, Eval_Loss, Eval_Runtime, Eval Samples/Second, Eval Steps/Second, Logging_Steps, Max_Steps



