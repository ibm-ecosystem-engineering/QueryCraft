[Default]
#This is the path to the folder where you have downloaded the repository
home_dir = /home/user/QueryCraft-The-SuperKnowa-SQL-Sculptor/
#Unique identifier of your experiment run. The name is expected to be in following format "YOURINDETIFIER_ModelName_Date"]
exp_name = exp_codellama7b_2802AllComponents

[DataIngestion]
#Relative path (from home_dir) of csv file to be ingested in db2 table
filename = input/datasets/people.csv
#Name of the new db2 table 
table_name= people


[ContextRetriever]
#Relative path (from home_dir) to the folder containing sqlite database dump in .sqlite format.
#You need to provide this field only if your db_type = sqlite.
input_database_folder= input/spider/database/
#Relative path (from home_dir) to the csv file with columns question, query, and db_id
input_data_file=input/datasets/spider.csv
#input_data_file = input/datasets/DB2_Context_Input.csv
#Select either of the two source databse - sqlite or db2
db_type = sqlite


[Finetune]
#Data collator to be used in trainer class
data_collator=DataCollatorForSeq2Seq
#Base pretrained model to finetune
model_name=codellama/CodeLlama-7b-Instruct-hf
#Relative path (from home_dir) to the text file which contains prompt tempelate
prompt_file_path=input/prompts/codellama_model.txt
#Select either of the two finetuning techniques supported - LoRA or QLoRA
finetune_type=LoRA
#Absolute path to the training dataset
#train_dataset =${Default:homne_dir}input/datasets/spiderTrainSetNewContext.csv
train_dataset =${Default:home_dir}input/datasets/${Default:exp_name}_contextRetriever.csv

[Inference]
inference_type=hf_batch_serial # vllm_batch, hf_batch_serial, hf_batch_multhread, hf_batch_accelarator
#Base pretrained model to draw inference on
model_name=codellama/CodeLlama-7b-Instruct-hf
#Either provide "NA" if you don't want to use finetuned model, or provide the absolute path to the finetuned adapter model weights
#finetuned_model = NA
finetuned_model = ${Default:home_dir}output/model/${Default:exp_name}
#Relative path (from home_dir) to dataset on which you want to draw the inferences
input_dataset = input/datasets/exp_codellama7b_2802_validSet.csv

[QueryCorrection]
#Absolute path of file on which you want to get an execution accuracy score
#input_dataset =  ${Default:homne_dir}output/inference/exp_codellama-13b_spider_0412.csv
input_dataset = ${Default:home_dir}output/inference/${Default:exp_name}_inference.csv

[EXEvaluator]
# provide db_type to run the code sqlite or db2. By default it is set to sqlite
db_type = 'sqlite'
#Relative path (from home_dir)to the folder containing database dump in .sqlite format.
input_database_folder=${Default:home_dir}input/spider/database/
#Absolute path of file on which you want to get an execution accuracy score
#input_dataset =  ${Default:homne_dir}output/inference/exp_codellama-13b_spider_0412.csv
input_dataset = ${Default:home_dir}output/inference/${Default:exp_name}_inference.csv



[QueryAnalysisDashboard]
#Absolute path of file on on which you want to get an execution accuracy score
folder_name =output/evalResults/
