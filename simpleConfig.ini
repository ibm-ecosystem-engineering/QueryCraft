[Default]
#This is the path to the folder where you have downloaded the repository
home_dir = /home/askyourcorpus/aditya_qc_experiments/QueryCraft-fork/
#Unique identifier of your experiment run. The name is expected to be in following format "YOURINDETIFIER_ModelName_Date"]
exp_name = db2__code_llama-7b

[DataIngestion]
#Relative path (from home_dir) of csv file to be ingested in db2 table
#CSV file for Loading
#filename = ../input/datasets/people.csv
filename = input/datasets/synthetic_data.csv
#Schema name - Database
schema_name = contract
# Table name for CSV data
table_name= contract
db_type = sqlite


[ContextRetriever]
#Relative path (from home_dir) to the folder containing sqlite database dump in .sqlite format.
#You need to provide this field only if your db_type = sqlite.
#input_database_folder= input/spider/database/
input_database_folder= code
#Relative path (from home_dir) to the csv file with columns question, query, and db_id
#input_data_file=input/datasets/spider.csv
input_data_file= input/_data/meta-llama_llama-3-70b-instruct_data.csv
#input_data_file = input/datasets/DB2_Context_Input.csv
#Select either of the two source databse - sqlite or db2
db_type = db2


[Finetune]
#Data collator to be used in trainer class DataCollatorForLanguageModeling, DataCollatorForSeq2Seq or DefaultDataCollator
data_collator=DataCollatorForLanguageModeling
#Base pretrained model to finetune
model_name=codellama/CodeLlama-7b-Instruct-hf
#Relative path (from home_dir) to the text file which contains prompt tempelate
prompt_file_path=input/prompts/codellama_model.txt
#Select either of the two finetuning techniques supported - LoRA or QLoRA
finetune_type=LoRA
#Absolute path to the training dataset
#train_dataset = ${Default:home_dir}input/datasets/spiderWithContext.csv 
#train_dataset = ${Default:home_dir}input/datasets/kaggleDBQAWithContext.csv 
train_dataset =${Default:home_dir}input/datasets/${Default:exp_name}_contextRetriever.csv

[Inference]
## hf_batch_serial vllm_batch
inference_type=vllm_batch
model_name=codellama/CodeLlama-7b-Instruct-hf
#finetuned_model = NA
finetuned_model = ${Default:home_dir}output/model/${Default:exp_name}
#input_dataset = input/datasets/exp_codellama7b_2802_validSet.csv
input_dataset = input/datasets/${Default:exp_name}_validSet.csv


[QueryCorrection]
#Absolute path of file on which you want to get an execution accuracy score
#input_dataset =  ${Default:homne_dir}output/inference/exp_codellama-13b_spider_0412.csv
input_dataset = ${Default:home_dir}output/inference__v2/evaluation_results_multi_shot_cot_synonyms_meta-llama_llama-3-70b-instruct.csv
expected_query_column = Expected
generated_query_column = Answers_meta-llama_llama-3-70b-instruct

[EXEvaluator]
# provide db_type to run the code sqlite or db2. By default it is set to sqlite
db_type = db2
input_dataset = ${Default:home_dir}output/inference_results-selected/_code_llama-7b_inference.csv
expected_query_column = query
generated_query_column = model_op
database_path= ${Default:home_dir}code/contract.sqlite
schema_name = SJC11494
#Relative path (from home_dir)to the folder containing database dump in .sqlite format.

[QueryAnalysisDashboard]
#Absolute path of file on which you want to get an execution accuracy score
folder_name =output/evalResults/
