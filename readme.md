# SuperKnowa SQL Sculptor

Welcome to the `SuperKnowa SQL Sculptor` repository, your comprehensive solution for fine-tuning Large Language Models (LLMs) for the task of generating SQL queries from natural language. This module is designed to streamline the process of adapting LLMs for Text to SQL tasks, providing a robust framework and pipeline that accelerates the initiation and fine-tuning process. Whether you're a developer or a user keen on harnessing the power of LLMs for database querying, `SuperKnowa SQL Sculptor` offers the tools and infrastructure to make your journey smoother and more efficient.

## Features

- **superConfig.ini**: A super configuration file to manage basic level settings for data ingestion, context retriever, fine-tuning, inference, query-correction, evaluation, and the query analysis dashboard among other services.
- **config.ini**: A configuration file to manage all settings for data ingestion, context retriever, fine-tuning, inference, query-correction, evaluation, and the query analysis dashboard among other services.
- **db2_connector.py**: This script provides global IBM DB2 connection for all other services.
- **db2_ingestion.py**: This script is used to insert the data into DB2 from a CSV file or any other delimiter file.
- **context_retriever.py**: This script extracts context directly from the SQLite database to inform and improve the accuracy of generated queries.
- **finetune.py**: Fine-tune your LLM specifically for the text-to-SQL task, optimizing its performance for your unique requirements.
- **inference.py**: Run the inference pipeline using either a pre-trained or a fine-tuned model to generate SQL queries from natural language inputs.
- **query_correction.py**: A script dedicated to correcting the syntax of generated SQL queries.
- **ex_evaluator.py**: A script dedicated to calculating the execution accuracy of generated SQL queries against an SQLite database, ensuring that your fine-tuned model performs optimally.
- **pipeline_result_csv_gen.py**: Extracts details of fine-tuning experiments and saves them to a CSV file, facilitating in-depth analysis through the query analysis dashboard.
- **streamlit_query_analysis_dashboard.py**: A Streamlit application that provides a comprehensive dashboard for analyzing the results of your fine-tuned model and conducting comparative analyses.

## Input

This module uses various inputs to train, evaluate, and optimize the performance of your model:

- **datasets/**: Contains datasets used for fine-tuning and evaluation of the Text to SQL model.
- **prompts/**: A collection of prompts used across different models for generation and fine-tuning tasks.
- **spider/**: The Spider database, serves as a benchmarking tool for evaluating the performance of your Text to SQL tasks.

## Output

The output directories are structured to organize the results of the different services and experiments:

- **benchmark/**: Stores benchmark results for Text to SQL tasks, allowing for performance comparison.
- **evalResults/**: A folder dedicated to storing the results of the evaluation service.
- **inference/**: Contains the results of the inference service, showcasing the SQL queries generated by your model.
- **log/**: Logs of the experiments are kept here for future reference and analysis.
- **model/**: A directory to store model checkpoints, facilitating easy retrieval and deployment of your fine-tuned models.

## Getting Started

To get started with `SuperKnowa-TextToSQL`, clone this repository to your local machine:

```bash
git clone https://github.com/YourOrganization/SuperKnowa-TextToSQL.git
cd SuperKnowa-TextToSQL
```

### Installation

Before diving into fine-tuning or inference, ensure that your environment is set up with all the necessary dependencies:

```bash
pip install -r requirements.txt
```

### Configuration

Configure your environment and services by editing the `config.ini` file. Make sure to specify the paths for datasets, models, and other services as per your setup.

### Fine-Tuning

To start fine-tuning your LLM for the Text to SQL task, run:

```bash
python finetune.py
```
<img src= "image/fine_tune.gif">

Follow the prompts to specify your dataset and model configuration.

### Inference

To generate SQL queries using your fine-tuned or pre-trained model, execute:

```bash
python inference.py
```
<img src= "image/Inference.gif">

### Evaluation

Evaluate the performance of your model against the SQLite database by running:

```bash
python EXevaluator.py
```
<img src= "image/evalution.gif">

## Query Analysis Dashboard

For a visual analysis of your fine-tuning experiments and generated SQL queries, launch the Streamlit dashboard:

```bash
streamlit run streamlit_query_analysis_dashboard.py
```

<img src= "image/Dashboard.gif">

## JupyterLab Installation and Setup 

1. Install JupyterLab
To begin, install JupyterLab using pip, which is the Python package manager:

`pip install jupyterlab`

2. Launch JupyterLab
Once JupyterLab is installed, navigate to your project directory using the terminal or command prompt. Then, execute the following command to launch JupyterLab:

```jupyter lab ```

3. Accessing Jupyter Lab
You can access JupyterLab through your web browser by navigating to the following URL:

[JupyterLab Link](http://localhost:5005/lab)

Insert Notebook Password
Ex. Password: ibm@123

This will open JupyterLab interface in your browser, allowing you to create and manage Jupyter notebooks and other interactive documents.


## License

This project is licensed under the Apache-2.0 license - see the [LICENSE](LICENSE) file for details.
